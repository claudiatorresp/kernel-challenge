{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from itertools import product, chain\n",
    "import functools \n",
    "import operator \n",
    "from csv import reader\n",
    "import regex as re\n",
    "\n",
    "from classifiers import *\n",
    "from metrics import *\n",
    "from kernels import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split # lui il va partir mais pour l'instant c'est pratique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_into_array(path):\n",
    "    with open(path, 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        X = list()\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                # row variable is a list that represents a row in csv\n",
    "                X.append(np.array(row[1]))\n",
    "                \n",
    "    X = np.array(X) ## dtype might be changed in something more convenient. For now, dtype = \"<U1\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0 = features_into_array(\"data/Xtr0.csv\")\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1 = features_into_array(\"data/Xtr1.csv\")\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2 = features_into_array(\"data/Xtr2.csv\")\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred, mode='SVM'):\n",
    "    n = y_true.shape[0]\n",
    "    if mode == 'SVM':\n",
    "        predictions = np.ones(n)\n",
    "        predictions[y_pred < 0] = 0\n",
    "    else:\n",
    "        predictions = np.zeros(n)\n",
    "        predictions[y_pred >= 0.5] = 1\n",
    "    \n",
    "    return np.sum(y_true == predictions) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCCTGTGCACATCTGCACCCCTGTTGTGGCCACAAAATGATCCGGCACCACCCAGTGGGAGACGACAGAGGTGGCAATGGGGTGTCGGCTCTGACGCCTCC'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mismatch Spectrum kernel\n",
    "\n",
    "For a fixed value k (that needs to be tuned), the k-spectrum kernel is defined as : \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "K(x,x^{\\prime}) := \\sum_{u \\in \\mathcal{A}^k} \\phi_{u}(x) \\phi_{u}(x^{\\prime})\n",
    "\\end{align*}\n",
    "\n",
    "We relax this constraint by authorizing each word of the alphabet to have up to m mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors(word, m):\n",
    "    \"\"\"\n",
    "    This gives neighbors that differ in exactly m places\n",
    "    \"\"\"\n",
    "    \n",
    "    char_list = list(['A', 'C','G','T'])\n",
    "    assert(m <= len(word))\n",
    "\n",
    "    if m == 0:\n",
    "        return [word]\n",
    "\n",
    "    r2 = neighbors(word[1:], m-1)\n",
    "    r = [c + r3 for r3 in r2 for c in char_list if c != word[0]]\n",
    "\n",
    "    if (m < len(word)):\n",
    "        r2 = neighbors(word[1:], m)\n",
    "        r += [word[0] + r3 for r3 in r2]\n",
    "\n",
    "    return r\n",
    "\n",
    "def neighbors2(pattern, m):\n",
    "    \"\"\"\n",
    "    This gives neighbors that differ in at most m places.\n",
    "    \"\"\"\n",
    "    return sum([neighbors(pattern, d2) for d2 in range(m + 1)], [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_substrings_mismatch(k,m):\n",
    "    \"\"\"\n",
    "    With a k spectrum kernel, let us find all the possible combinations of chars of size k in the sequence x\n",
    "    This way, we could index them in the sequence x\n",
    "    \"\"\"\n",
    "    char_list = list(['A', 'C','G','T'])\n",
    "    alphabet_tuples = list(product(char_list,repeat=k))\n",
    "    alphabet = list()\n",
    "    for i in alphabet_tuples:\n",
    "        word = functools.reduce(operator.add, (i))\n",
    "        l= [word]+neighbors2(word,m)[1:]\n",
    "        alphabet.append(l)\n",
    "    return alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_indexing_mismatch(X, alphabet):\n",
    "    \"\"\"\n",
    "    Transforms an input array into a sparse matrix encoding the number of occurences of each letter of\n",
    "    the alphabet composed of substrings of size k\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    n = X.shape[0]\n",
    "    D = np.zeros((n,len(alphabet)))\n",
    "    for x in X:\n",
    "        d = dict()\n",
    "        for letters in alphabet :\n",
    "            cnt = 0\n",
    "            for letter in letters:\n",
    "                cnt += len(re.findall(letter, x, overlapped=True))\n",
    "            d[letters[0]] = cnt\n",
    "        data = np.array(list(d.items()))\n",
    "        D[i] = data[:,1]\n",
    "        i+=1\n",
    "    D = csr_matrix(D, dtype = int)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 17, 13,  7, 19, 18, 13, 17, 13, 16, 17, 12, 11, 10, 17,  8,\n",
       "        16, 19, 19, 16, 20, 26, 21, 14, 14, 20, 19, 15, 12, 18, 19, 11,\n",
       "        15, 18, 16, 13, 14, 24, 21, 16, 19, 19, 24, 18, 12, 20, 19, 11,\n",
       "         6, 13, 10, 10, 18, 16, 14, 14, 16, 20, 20, 17,  3, 11, 17,  8],\n",
       "       [20, 19, 10, 19, 17, 15,  8, 20, 11, 16,  9, 14, 22, 18, 17, 26,\n",
       "        18, 12, 12, 19, 18, 19, 11, 15, 12,  6,  2, 13, 19, 18, 12, 25,\n",
       "        10,  9, 11, 14,  9,  9,  3, 15,  5,  2,  2, 13, 18, 16, 10, 19,\n",
       "        20, 20, 17, 31, 18, 21, 12, 27, 16, 12,  9, 23, 28, 25, 20, 34],\n",
       "       [36, 24, 26, 26, 24, 15, 10, 19, 27, 14, 16, 17, 26, 15, 14, 18,\n",
       "        25, 17, 17, 17, 18,  9,  6,  9, 10,  9,  9, 10, 18,  7, 12, 14,\n",
       "        24, 13, 15, 13, 21,  7, 12, 11, 12, 14, 14, 13, 17, 13, 12, 14,\n",
       "        28, 14, 16, 16, 14, 11, 10, 11, 16, 13, 13, 12, 17, 12, 17, 11],\n",
       "       [32, 22, 22, 22, 20, 12, 12, 16, 23, 16, 18, 17, 19, 10, 18, 18,\n",
       "        24, 14, 16, 13, 15, 13, 11,  8, 16,  7, 13,  9, 12, 11, 11, 14,\n",
       "        22, 13, 17, 17, 14, 11,  9, 13, 17,  9, 19, 20, 16, 12, 18, 16,\n",
       "        20, 11, 19, 13, 15, 10, 12, 10, 16, 16, 16, 17, 16, 14, 18, 20],\n",
       "       [23, 17, 24, 17, 12, 13, 19, 15, 23, 19, 20, 17, 16, 10, 23, 11,\n",
       "        17, 13, 17, 15, 14, 13, 12, 13, 14, 10, 16, 10, 14, 16, 16, 15,\n",
       "        21, 15, 20, 15, 21, 10, 10, 18, 17, 17, 20, 15, 13, 15, 14, 14,\n",
       "        16, 13, 18, 12, 14, 16, 10, 15, 17, 14, 17, 15, 15, 14, 11, 14]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = all_possible_substrings_mismatch(3,1)\n",
    "pre_indexing_mismatch(Xtr0[:5],alphabet).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mismatch_spectrum_kernel(X_train, X_val, k, mode=\"train\", m=1):\n",
    "    \"\"\"\n",
    "    Computes the spectrum kernels for X_train (n_train x n_train) and X_validation (on the RKHS generated(?) by\n",
    "    X_train's samples) which is of shape n_validation x n_train\n",
    "    \"test\" mode only gives as output the testing kernel\n",
    "    \"\"\"\n",
    "    alphabet = all_possible_substrings_mismatch(k,m)\n",
    "    \n",
    "    D_train = pre_indexing_mismatch(X_train,alphabet).toarray()\n",
    "    D_val = pre_indexing_mismatch(X_val,alphabet).toarray()\n",
    "    \n",
    "    K_val = np.inner(D_val, D_train)\n",
    "    K_val = K_val.astype('float')\n",
    "    if mode == \"test\":\n",
    "        return(K_val)\n",
    "    else:\n",
    "        K_train = np.inner(D_train, D_train)\n",
    "        K_train = K_train.astype('float')\n",
    "        \n",
    "        return(K_train, K_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16158., 14442., 15070., 15164., 15408.],\n",
       "       [15926., 13732., 15764., 15894., 15986.],\n",
       "       [15814., 15190., 15012., 14900., 15256.],\n",
       "       [14978., 16138., 15872., 15384., 15206.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example \n",
    "\n",
    "mismatch_spectrum_kernel(Xtr0[:5], Xtr0[16:20], 3,mode='test',m=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_0, Xval_0, ytr0, yval0 = train_test_split(Xtr0, Ytr0, test_size=0.2, random_state=42)\n",
    "Xtr_1, Xval_1, ytr1, yval1 = train_test_split(Xtr1, Ytr1, test_size=0.2, random_state=42)\n",
    "Xtr_2, Xval_2, ytr2, yval2 = train_test_split(Xtr2, Ytr2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0, K_val0 = mismatch_spectrum_kernel(Xtr_0, Xval_0, 3, mode=\"train\",m=1)\n",
    "K_tr1, K_val1 = mismatch_spectrum_kernel(Xtr_1, Xval_1, 3, mode=\"train\",m=1)\n",
    "K_tr2, K_val2 = mismatch_spectrum_kernel(Xtr_2, Xval_2, 3, mode=\"train\",m=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- KRR for dataset 0 --------------------\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = -238825242745066.0312, accuracy = 0.509375\n",
      "Validation: loss = 2461925.3800, accuracy = 0.482500\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = -157179.9545, accuracy = 0.621250\n",
      "Validation: loss = 108.1015, accuracy = 0.582500\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = -328.0022, accuracy = 0.622500\n",
      "Validation: loss = 108.1069, accuracy = 0.585000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 431.6183, accuracy = 0.622500\n",
      "Validation: loss = 108.1057, accuracy = 0.585000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 430.8024, accuracy = 0.622500\n",
      "Validation: loss = 108.1056, accuracy = 0.585000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 430.8338, accuracy = 0.622500\n",
      "Validation: loss = 108.1055, accuracy = 0.585000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 430.8331, accuracy = 0.622500\n",
      "Validation: loss = 108.1054, accuracy = 0.585000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 430.8282, accuracy = 0.621875\n",
      "Validation: loss = 108.1039, accuracy = 0.585000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 430.7806, accuracy = 0.623125\n",
      "Validation: loss = 108.0897, accuracy = 0.582500\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 430.3971, accuracy = 0.624375\n",
      "Validation: loss = 107.9756, accuracy = 0.592500\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 428.8255, accuracy = 0.622500\n",
      "Validation: loss = 107.5373, accuracy = 0.580000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 422.9309, accuracy = 0.610625\n",
      "Validation: loss = 106.1348, accuracy = 0.580000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 406.7448, accuracy = 0.600000\n",
      "Validation: loss = 102.2493, accuracy = 0.590000\n",
      "\n",
      "-------------------- KRR for dataset 1 --------------------\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 733605170983340.7500, accuracy = 0.501875\n",
      "Validation: loss = 6208885.9400, accuracy = 0.477500\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = -97837.6011, accuracy = 0.618125\n",
      "Validation: loss = 111.3831, accuracy = 0.565000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 108.8614, accuracy = 0.620000\n",
      "Validation: loss = 111.3601, accuracy = 0.565000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 431.6073, accuracy = 0.620000\n",
      "Validation: loss = 111.3640, accuracy = 0.565000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 437.8342, accuracy = 0.620000\n",
      "Validation: loss = 111.3640, accuracy = 0.565000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 437.8933, accuracy = 0.620000\n",
      "Validation: loss = 111.3640, accuracy = 0.565000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 437.8930, accuracy = 0.620000\n",
      "Validation: loss = 111.3637, accuracy = 0.565000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 437.8863, accuracy = 0.620000\n",
      "Validation: loss = 111.3607, accuracy = 0.565000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 437.8216, accuracy = 0.618750\n",
      "Validation: loss = 111.3321, accuracy = 0.567500\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 437.3303, accuracy = 0.616875\n",
      "Validation: loss = 111.1266, accuracy = 0.570000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 435.5206, accuracy = 0.617500\n",
      "Validation: loss = 110.4605, accuracy = 0.555000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 429.0249, accuracy = 0.621250\n",
      "Validation: loss = 108.5170, accuracy = 0.565000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 409.5972, accuracy = 0.612500\n",
      "Validation: loss = 102.9826, accuracy = 0.570000\n",
      "\n",
      "-------------------- KRR for dataset 2 --------------------\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 216079036775710009875661208944640.0000, accuracy = 0.503125\n",
      "Validation: loss = 54147497318342533224087693557760.0000, accuracy = 0.510000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = -7077.7276, accuracy = 0.710000\n",
      "Validation: loss = 122.2413, accuracy = 0.650000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = -178.9398, accuracy = 0.710625\n",
      "Validation: loss = 122.2291, accuracy = 0.652500\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 489.3009, accuracy = 0.710000\n",
      "Validation: loss = 122.2266, accuracy = 0.652500\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 491.2306, accuracy = 0.710000\n",
      "Validation: loss = 122.2265, accuracy = 0.652500\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 491.2923, accuracy = 0.710000\n",
      "Validation: loss = 122.2265, accuracy = 0.652500\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 491.2921, accuracy = 0.710000\n",
      "Validation: loss = 122.2263, accuracy = 0.652500\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 491.2860, accuracy = 0.710625\n",
      "Validation: loss = 122.2249, accuracy = 0.652500\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 491.2262, accuracy = 0.710625\n",
      "Validation: loss = 122.2112, accuracy = 0.652500\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 490.7197, accuracy = 0.710625\n",
      "Validation: loss = 122.0953, accuracy = 0.655000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 488.2245, accuracy = 0.710000\n",
      "Validation: loss = 121.5073, accuracy = 0.655000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 475.5718, accuracy = 0.708125\n",
      "Validation: loss = 118.3545, accuracy = 0.662500\n",
      "***********lambda = 10***********\n",
      "Training: loss = 431.5828, accuracy = 0.698750\n",
      "Validation: loss = 107.6704, accuracy = 0.652500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "print(20 * \"-\"+ \" KRR for dataset 0 \" + 20 * \"-\")\n",
    "print('')\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KRR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print('')\n",
    "\n",
    "print(20 * \"-\"+ \" KRR for dataset 1 \" + 20 * \"-\")\n",
    "print('')\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = KRR(K_tr1, ytr1[:,1], K_val1, yval1[:,1], lambdas)\n",
    "print('')\n",
    "\n",
    "print(20 * \"-\"+ \" KRR for dataset 2 \" + 20 * \"-\")\n",
    "print('')\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = KRR(K_tr2, ytr2[:,1], K_val2, yval2[:,1], lambdas)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- SVM for dataset 0 --------------------\n",
      "\n",
      "---------------  lambda = 1e-10  ---------------\n",
      "Training: loss = 0.826924, accuracy = 0.616875\n",
      "Validation: loss = 0.873618, accuracy = 0.590000\n",
      "---------------  lambda = 1e-09  ---------------\n",
      "Training: loss = 0.826926, accuracy = 0.616875\n",
      "Validation: loss = 0.873605, accuracy = 0.590000\n",
      "---------------  lambda = 1e-08  ---------------\n",
      "Training: loss = 0.826925, accuracy = 0.616875\n",
      "Validation: loss = 0.873604, accuracy = 0.590000\n",
      "---------------  lambda = 1e-07  ---------------\n",
      "Training: loss = 0.826925, accuracy = 0.616875\n",
      "Validation: loss = 0.873604, accuracy = 0.590000\n",
      "---------------  lambda = 1e-06  ---------------\n",
      "Training: loss = 0.826925, accuracy = 0.617500\n",
      "Validation: loss = 0.873569, accuracy = 0.590000\n",
      "---------------  lambda = 1e-05  ---------------\n",
      "Training: loss = 0.826925, accuracy = 0.617500\n",
      "Validation: loss = 0.873547, accuracy = 0.590000\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.826925, accuracy = 0.617500\n",
      "Validation: loss = 0.873386, accuracy = 0.592500\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.826952, accuracy = 0.616875\n",
      "Validation: loss = 0.872306, accuracy = 0.597500\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.828331, accuracy = 0.623125\n",
      "Validation: loss = 0.860766, accuracy = 0.600000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.833416, accuracy = 0.618125\n",
      "Validation: loss = 0.851908, accuracy = 0.602500\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.852687, accuracy = 0.606875\n",
      "Validation: loss = 0.867277, accuracy = 0.595000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.934975, accuracy = 0.524375\n",
      "Validation: loss = 0.984448, accuracy = 0.497500\n",
      "\n",
      "-------------------- SVM for dataset 1 --------------------\n",
      "\n",
      "---------------  lambda = 1e-10  ---------------\n",
      "Training: loss = 0.815568, accuracy = 0.630625\n",
      "Validation: loss = 0.935490, accuracy = 0.572500\n",
      "---------------  lambda = 1e-09  ---------------\n",
      "Training: loss = 0.815560, accuracy = 0.630625\n",
      "Validation: loss = 0.935458, accuracy = 0.572500\n",
      "---------------  lambda = 1e-08  ---------------\n",
      "Training: loss = 0.815559, accuracy = 0.630625\n",
      "Validation: loss = 0.935453, accuracy = 0.572500\n",
      "---------------  lambda = 1e-07  ---------------\n",
      "Training: loss = 0.815559, accuracy = 0.630625\n",
      "Validation: loss = 0.935453, accuracy = 0.572500\n",
      "---------------  lambda = 1e-06  ---------------\n",
      "Training: loss = 0.815559, accuracy = 0.630625\n",
      "Validation: loss = 0.935453, accuracy = 0.572500\n",
      "---------------  lambda = 1e-05  ---------------\n",
      "Training: loss = 0.815559, accuracy = 0.630625\n",
      "Validation: loss = 0.935447, accuracy = 0.572500\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.815560, accuracy = 0.631250\n",
      "Validation: loss = 0.935255, accuracy = 0.570000\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.815597, accuracy = 0.631875\n",
      "Validation: loss = 0.932313, accuracy = 0.562500\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.817223, accuracy = 0.628125\n",
      "Validation: loss = 0.928043, accuracy = 0.565000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.821261, accuracy = 0.630625\n",
      "Validation: loss = 0.919914, accuracy = 0.572500\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.844208, accuracy = 0.616250\n",
      "Validation: loss = 0.908579, accuracy = 0.560000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.941333, accuracy = 0.556250\n",
      "Validation: loss = 1.005575, accuracy = 0.492500\n",
      "\n",
      "-------------------- SVM for dataset 2 --------------------\n",
      "\n",
      "---------------  lambda = 1e-10  ---------------\n",
      "Training: loss = 0.659298, accuracy = 0.726875\n",
      "Validation: loss = 0.783921, accuracy = 0.652500\n",
      "---------------  lambda = 1e-09  ---------------\n",
      "Training: loss = 0.659284, accuracy = 0.726875\n",
      "Validation: loss = 0.783821, accuracy = 0.652500\n",
      "---------------  lambda = 1e-08  ---------------\n",
      "Training: loss = 0.659281, accuracy = 0.726875\n",
      "Validation: loss = 0.783831, accuracy = 0.652500\n",
      "---------------  lambda = 1e-07  ---------------\n",
      "Training: loss = 0.659281, accuracy = 0.726875\n",
      "Validation: loss = 0.783831, accuracy = 0.652500\n",
      "---------------  lambda = 1e-06  ---------------\n",
      "Training: loss = 0.659281, accuracy = 0.726875\n",
      "Validation: loss = 0.783831, accuracy = 0.652500\n",
      "---------------  lambda = 1e-05  ---------------\n",
      "Training: loss = 0.659281, accuracy = 0.726875\n",
      "Validation: loss = 0.783818, accuracy = 0.652500\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.659282, accuracy = 0.727500\n",
      "Validation: loss = 0.783864, accuracy = 0.652500\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.659343, accuracy = 0.722500\n",
      "Validation: loss = 0.785096, accuracy = 0.650000\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.660351, accuracy = 0.720625\n",
      "Validation: loss = 0.777928, accuracy = 0.657500\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.664095, accuracy = 0.712500\n",
      "Validation: loss = 0.768097, accuracy = 0.652500\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.687812, accuracy = 0.707500\n",
      "Validation: loss = 0.750128, accuracy = 0.652500\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.830920, accuracy = 0.676875\n",
      "Validation: loss = 0.857218, accuracy = 0.625000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-10, 2)]\n",
    "\n",
    "print(20 * \"-\"+ \" SVM for dataset 0 \" + 20 * \"-\")\n",
    "print('')\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print('')\n",
    "\n",
    "print(20 * \"-\"+ \" SVM for dataset 1 \" + 20 * \"-\")\n",
    "print('')\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = SVM(K_tr1, ytr1[:,1], K_val1, yval1[:,1], lambdas)\n",
    "print('')\n",
    "\n",
    "print(20 * \"-\"+ \" SVM for dataset 2 \" + 20 * \"-\")\n",
    "print('')\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = SVM(K_tr2, ytr2[:,1], K_val2, yval2[:,1], lambdas)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the accuracy on sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte0_seq = features_into_array(\"data/Xte0.csv\")\n",
    "Xte1_seq = features_into_array(\"data/Xte1.csv\")\n",
    "Xte2_seq = features_into_array(\"data/Xte2.csv\")\n",
    "\n",
    "K_te0 = mismatch_spectrum_kernel(Xtr_0, Xte0_seq, 3, mode=\"test\",m=1)\n",
    "K_te1 = mismatch_spectrum_kernel(Xtr_1, Xte1_seq, 3, mode=\"test\",m=1)\n",
    "K_te2 = mismatch_spectrum_kernel(Xtr_2, Xte2_seq, 3, mode=\"test\",m=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving predictions\n",
      "saved predictions\n"
     ]
    }
   ],
   "source": [
    "test_kernels = [K_te0, K_te1, K_te2]\n",
    "#test_alphas = [alphas_tr0[-4], alphas_tr1[-4], alphas_tr2[-3]] # il faut choisir l'alpha associé à un bon lambda!\n",
    "test_alphas = [alphas_tr0[9], alphas_tr1[4], alphas_tr2[8]]\n",
    "write_predictions_csv(test_kernels, test_alphas, path =\"data/mismatch_Ytest_sequences.csv\", mode=\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim",
   "language": "python",
   "name": "optim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
