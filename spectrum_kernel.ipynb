{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from itertools import product\n",
    "import functools \n",
    "import operator \n",
    "import regex as re\n",
    "import time\n",
    "\n",
    "from classifiers import *\n",
    "from metrics import *\n",
    "from kernels import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split # lui il va partir mais pour l'instant c'est pratique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "def features_into_array(path):\n",
    "    with open(path, 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        X = list()\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                # row variable is a list that represents a row in csv\n",
    "                X.append(np.array(row[1]))\n",
    "                \n",
    "    X = np.array(X) ## dtype might be changed in something more convenient. For now, dtype = \"<U1\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0 = features_into_array(\"data/Xtr0.csv\")\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1 = features_into_array(\"data/Xtr1.csv\")\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2 = features_into_array(\"data/Xtr2.csv\")\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCCTGTGCACATCTGCACCCCTGTTGTGGCCACAAAATGATCCGGCACCACCCAGTGGGAGACGACAGAGGTGGCAATGGGGTGTCGGCTCTGACGCCTCC'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum kernel\n",
    "\n",
    "For a fixed value k (that needs to be tuned), the k-spectrum kernel is defined as : \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "K(x,x^{\\prime}) := \\sum_{u \\in \\mathcal{A}^k} \\phi_{u}(x) \\phi_{u}(x^{\\prime})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_substrings(k):\n",
    "    \"\"\"\n",
    "    With a k spectrum kernel, let us find all the possible combinations of chars of size k in the sequence x\n",
    "    This way, we could index them in the sequence x\n",
    "    \"\"\"\n",
    "    char_list = list(['A', 'C','G','T'])\n",
    "    alphabet_tuples = list(product(char_list,repeat=k))\n",
    "    alphabet = dict()\n",
    "    idx=0\n",
    "    for i in alphabet_tuples:\n",
    "        alphabet[functools.reduce(operator.add, (i))] = idx\n",
    "        idx += 1\n",
    "        #alphabet.append(functools.reduce(operator.add, (i)))\n",
    "    return alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example\n",
    "\n",
    "len(all_possible_substrings(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : a function that computes occurences \n",
    "## with overlapping option without calling regex if we have remaining time (lol)\n",
    "\n",
    "def pre_indexing_by_sequence(x,k):\n",
    "    alphabet = all_possible_substrings(k)\n",
    "    return dict((letter, len(re.findall(letter, x, overlapped=True))) for letter in alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_indexing(X, k, alphabet=None):\n",
    "    \"\"\"\n",
    "    Transforms an input array into a sparse matrix encoding the number of occurences of each letter of\n",
    "    the alphabet composed of substrings of size k\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    n = X.shape[0]\n",
    "    if alphabet is None:\n",
    "        alphabet = all_possible_substrings(k)\n",
    "    D = np.zeros((n,len(alphabet)))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        idx=0\n",
    "        while idx + k < len(X[i]):\n",
    "            D[i, alphabet[X[i][idx:idx+k]]] += 1\n",
    "            idx += 1\n",
    "    \"\"\"\n",
    "    for x in X:\n",
    "        d = dict((letter, len(re.findall(letter, x, overlapped=True))) \n",
    "                             for letter in alphabet)\n",
    "        data = np.array(list(d.items()))\n",
    "        D[i] = data[:,1]\n",
    "        i+=1\n",
    "    \"\"\"\n",
    "    D = csr_matrix(D, dtype = int)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_indexing(X, k, alphabet=None):\n",
    "    \"\"\"\n",
    "    Transforms an input array into a sparse matrix encoding the number of occurences of each letter of\n",
    "    the alphabet composed of substrings of size k\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    n = X.shape[0]\n",
    "    if alphabet is None:\n",
    "        alphabet = all_possible_substrings(k)\n",
    "    D = np.zeros((n,len(alphabet)))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        idx=0\n",
    "        while idx + k < len(X[i]):\n",
    "            D[i, alphabet[X[i][idx:idx+k]]] += 1\n",
    "            idx += 1\n",
    "    \"\"\"\n",
    "    for x in X:\n",
    "        d = dict((letter, len(re.findall(letter, x, overlapped=True))) \n",
    "                             for letter in alphabet)\n",
    "        data = np.array(list(d.items()))\n",
    "        D[i] = data[:,1]\n",
    "        i+=1\n",
    "    \"\"\"\n",
    "    D = csr_matrix(D, dtype = int)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 65536)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example\n",
    "pre_indexing(Xtr0,8).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 0.760915994644165 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "start_time = time.time()\n",
    "alphabet_6 = all_possible_substrings(k)\n",
    "mm = pre_indexing(Xtr0, 6, alphabet=alphabet_6)\n",
    "print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_kernel(X_train, X_val, k, alphabet=None, mode=\"train\"):\n",
    "    \"\"\"\n",
    "    Computes the spectrum kernels for X_train (n_train x n_train) and X_validation (on the RKHS generated(?) by\n",
    "    X_train's samples) which is of shape n_validation x n_train\n",
    "    \"test\" mode only gives as output the testing kernel\n",
    "    \"\"\"\n",
    "    if alphabet is None:\n",
    "        D_train = pre_indexing(X_train,k).toarray()\n",
    "        D_val = pre_indexing(X_val,k).toarray()\n",
    "    else:\n",
    "        D_train = pre_indexing(X_train,k,alphabet).toarray()\n",
    "        D_val = pre_indexing(X_val,k,alphabet).toarray()\n",
    "\n",
    "    K_val = np.inner(D_val, D_train)\n",
    "    K_val = K_val.astype('float')\n",
    "    if mode == \"test\":\n",
    "        return(K_val)\n",
    "    else:\n",
    "        K_train = np.inner(D_train, D_train)\n",
    "        K_train = K_train.astype('float')\n",
    "        \n",
    "        return(K_train, K_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_, Xval0_, ytr0, yval0 = train_test_split(Xtr0, Ytr0, test_size=0.5, random_state=42)\n",
    "Xtr1_, Xval1_, ytr1, yval1 = train_test_split(Xtr1, Ytr1, test_size=0.5, random_state=42)\n",
    "Xtr2_, Xval2_, ytr2, yval2 = train_test_split(Xtr2, Ytr2, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 0.008453130722045898 seconds ---\n",
      "--- Computed kernel in 7.895594120025635 seconds ---\n",
      "--- Computed kernel in 9.161088943481445 seconds ---\n",
      "--- Computed kernel in 8.731503009796143 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "start_time = time.time()\n",
    "alphabet_8 = all_possible_substrings(k)\n",
    "print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "\n",
    "K_tr0, K_val0 = spectrum_kernel(Xtr0_, Xval0_, k, alphabet= alphabet_8, mode=\"train\")\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "K_tr1, K_val1 = spectrum_kernel(Xtr1_, Xval1_, k, alphabet= alphabet_8,mode=\"train\")\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "K_tr2, K_val2 = spectrum_kernel(Xtr2_, Xval2_, k, alphabet= alphabet_8,mode=\"train\")\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* KRR for dataset 0*************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 13589139989960126.0000, accuracy = 0.489375\n",
      "Validation: loss = 1308657.5175, accuracy = 0.492500\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 1515.9968, accuracy = 0.622500\n",
      "Validation: loss = 108.1055, accuracy = 0.585000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 424.2567, accuracy = 0.622500\n",
      "Validation: loss = 108.1055, accuracy = 0.585000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 431.0139, accuracy = 0.622500\n",
      "Validation: loss = 108.1056, accuracy = 0.585000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 430.9448, accuracy = 0.622500\n",
      "Validation: loss = 108.1055, accuracy = 0.585000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 430.9434, accuracy = 0.622500\n",
      "Validation: loss = 108.1055, accuracy = 0.585000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 430.9396, accuracy = 0.622500\n",
      "Validation: loss = 108.1045, accuracy = 0.582500\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 430.9014, accuracy = 0.622500\n",
      "Validation: loss = 108.0950, accuracy = 0.582500\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 430.5787, accuracy = 0.622500\n",
      "Validation: loss = 108.0143, accuracy = 0.582500\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 429.1783, accuracy = 0.618125\n",
      "Validation: loss = 107.6554, accuracy = 0.585000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 425.9184, accuracy = 0.609375\n",
      "Validation: loss = 106.8673, accuracy = 0.580000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 413.3631, accuracy = 0.603125\n",
      "Validation: loss = 103.9434, accuracy = 0.582500\n",
      "***********lambda = 10***********\n",
      "Training: loss = 401.8862, accuracy = 0.541875\n",
      "Validation: loss = 101.5393, accuracy = 0.527500\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "print(\"************* KRR for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KRR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************KLR for dataset 0*************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.6624, accuracy = 0.623125\n",
      "Validation: loss = 0.6710, accuracy = 0.582500\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.6627, accuracy = 0.621875\n",
      "Validation: loss = 0.6705, accuracy = 0.592500\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.6641, accuracy = 0.615000\n",
      "Validation: loss = 0.6700, accuracy = 0.592500\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.6677, accuracy = 0.610000\n",
      "Validation: loss = 0.6723, accuracy = 0.590000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6797, accuracy = 0.598750\n",
      "Validation: loss = 0.6829, accuracy = 0.580000\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-4,1)]\n",
    "\n",
    "print(\"*************KLR for dataset 0*************\\n\")\n",
    "alphas_tr0_klr, loss_tr0_klr, acc_0_klr, loss_val0_klr, acc_val0_klr = KLR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas, tresh=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 1e-10  ---------------\n",
      "Training: loss = 0.826925, accuracy = 0.616875\n",
      "Validation: loss = 0.873604, accuracy = 0.590000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-34d0b96482c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"************* SVM for dataset 0*************\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0malphas_tr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKtr0_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKval0_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/Macintosh HD/Documents/Telecom/3A/S2/Kernel Methods/HW/Challenge/classifiers.py\u001b[0m in \u001b[0;36mSVM\u001b[0;34m(K, y, K_val, y_val, lambd)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0msolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'show_progress'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0msol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mqp\u001b[0;34m(P, q, G, h, A, b, solver, kktsolver, initvals, **kwargs)\u001b[0m\n\u001b[1;32m   4483\u001b[0m             'residual as dual infeasibility certificate': dinfres}\n\u001b[1;32m   4484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4485\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconeqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkktsolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mconeqp\u001b[0;34m(P, q, G, h, dims, A, b, initvals, kktsolver, xnewcopy, xdot, xaxpy, xscal, ynewcopy, ydot, yaxpy, yscal, **kwargs)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         \u001b[0;31m# On exit, they contain ux, uy, uz.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArithmeticError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miters\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/coneprog.py\u001b[0m in \u001b[0;36mkktsolver\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m   1979\u001b[0m              \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkkt_chol2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m          \u001b[0;32mdef\u001b[0m \u001b[0mkktsolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1981\u001b[0;31m              \u001b[0;32mreturn\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxnewcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxnewcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/cvxopt/misc.py\u001b[0m in \u001b[0;36mfactor\u001b[0;34m(W, H, Df)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m             \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyrk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1452\u001b[0m             if mnl: base.syrk(F['Dfs'], F['S'], trans = 'T', beta = 1.0, \n\u001b[1;32m   1453\u001b[0m                 partial = True)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-10, 0)]\n",
    "print(\"************* SVM for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(Ktr0_, ytr0[:,1], Kval0_, yval0[:,1], lambdas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the accuracy on sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte0_seq = features_into_array(\"data/Xte0.csv\")\n",
    "Xte1_seq = features_into_array(\"data/Xte1.csv\")\n",
    "Xte2_seq = features_into_array(\"data/Xte2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernels = [K_te0, K_te1, K_te2]\n",
    "#test_alphas = [alphas_tr0[-4], alphas_tr1[-4], alphas_tr2[-3]] # il faut choisir l'alpha associé à un bon lambda!\n",
    "test_alphas = [alphas_tr0[0], alphas_tr1[0], alphas_tr2[0]]\n",
    "write_predictions_csv(test_kernels, test_alphas, path =\"data/Ytest_sequences.csv\", mode=\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
