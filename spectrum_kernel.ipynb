{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from itertools import product\n",
    "import functools \n",
    "import operator \n",
    "import regex as re\n",
    "import time\n",
    "\n",
    "from classifiers import *\n",
    "from metrics import *\n",
    "from kernels import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split # lui il va partir mais pour l'instant c'est pratique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "def features_into_array(path):\n",
    "    with open(path, 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        X = list()\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                # row variable is a list that represents a row in csv\n",
    "                X.append(np.array(row[1]))\n",
    "                \n",
    "    X = np.array(X) ## dtype might be changed in something more convenient. For now, dtype = \"<U1\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0 = features_into_array(\"data/Xtr0.csv\")\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1 = features_into_array(\"data/Xtr1.csv\")\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2 = features_into_array(\"data/Xtr2.csv\")\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCCTGTGCACATCTGCACCCCTGTTGTGGCCACAAAATGATCCGGCACCACCCAGTGGGAGACGACAGAGGTGGCAATGGGGTGTCGGCTCTGACGCCTCC'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum kernel\n",
    "\n",
    "For a fixed value k (that needs to be tuned), the k-spectrum kernel is defined as : \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "K(x,x^{\\prime}) := \\sum_{u \\in \\mathcal{A}^k} \\phi_{u}(x) \\phi_{u}(x^{\\prime})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_substrings(k):\n",
    "    \"\"\"\n",
    "    With a k spectrum kernel, let us find all the possible combinations of chars of size k in the sequence x\n",
    "    This way, we could index them in the sequence x\n",
    "    \"\"\"\n",
    "    char_list = list(['A', 'C','G','T'])\n",
    "    alphabet_tuples = list(product(char_list,repeat=k))\n",
    "    alphabet = dict()\n",
    "    idx=0\n",
    "    for i in alphabet_tuples:\n",
    "        alphabet[functools.reduce(operator.add, (i))] = idx\n",
    "        idx += 1\n",
    "        #alphabet.append(functools.reduce(operator.add, (i)))\n",
    "    return alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example\n",
    "\n",
    "len(all_possible_substrings(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : a function that computes occurences \n",
    "## with overlapping option without calling regex if we have remaining time (lol)\n",
    "\n",
    "def pre_indexing_by_sequence(x,k):\n",
    "    alphabet = all_possible_substrings(k)\n",
    "    return dict((letter, len(re.findall(letter, x, overlapped=True))) for letter in alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_indexing(X, k, alphabet=None):\n",
    "    \"\"\"\n",
    "    Transforms an input array into a sparse matrix encoding the number of occurences of each letter of\n",
    "    the alphabet composed of substrings of size k\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    n = X.shape[0]\n",
    "    if alphabet is None:\n",
    "        alphabet = all_possible_substrings(k)\n",
    "    D = np.zeros((n,len(alphabet)))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        idx=0\n",
    "        while idx + k < len(X[i]):\n",
    "            D[i, alphabet[X[i][idx:idx+k]]] += 1\n",
    "            idx += 1\n",
    "    \"\"\"\n",
    "    for x in X:\n",
    "        d = dict((letter, len(re.findall(letter, x, overlapped=True))) \n",
    "                             for letter in alphabet)\n",
    "        data = np.array(list(d.items()))\n",
    "        D[i] = data[:,1]\n",
    "        i+=1\n",
    "    \"\"\"\n",
    "    D = csr_matrix(D, dtype = int)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 65536)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example\n",
    "pre_indexing(Xtr0,8).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 0.760915994644165 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "start_time = time.time()\n",
    "alphabet_6 = all_possible_substrings(k)\n",
    "mm = pre_indexing(Xtr0, 6, alphabet=alphabet_6)\n",
    "print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_kernel(X_train, X_val, X_test, k, alphabet=None):\n",
    "    # Kill two birds with one stone and compute K_train, K_val and K_test all at once.\n",
    "    \"\"\"\n",
    "    Computes the spectrum kernels for X_train (n_train x n_train), X_validation and X_test\n",
    "    (on the RKHS generated by X_train's samples) which is of shape n_validation x n_train (resp n_test x n_train)\n",
    "    \"\"\"\n",
    "    if alphabet is None:\n",
    "        #D_train = pre_indexing(X_train,k).toarray()\n",
    "        #D_val = pre_indexing(X_val,k).toarray()\n",
    "        D_train = pre_indexing(X_train,k)\n",
    "        D_val = pre_indexing(X_val,k)\n",
    "        D_test = pre_indexing(X_test,k)\n",
    "        \n",
    "    else:\n",
    "        #D_train = pre_indexing(X_train,k,alphabet).toarray()\n",
    "        #D_val = pre_indexing(X_val,k,alphabet).toarray()\n",
    "        D_train = pre_indexing(X_train,k,alphabet)\n",
    "        D_val = pre_indexing(X_val,k,alphabet)\n",
    "        D_test = pre_indexing(X_test,k,alphabet)\n",
    "        \n",
    "        \n",
    "    #K_val = np.inner(D_val, D_train)\n",
    "    #K_val = K_val.astype('float')\n",
    "    \n",
    "    K_train = D_train.dot(D_train.transpose())\n",
    "    K_train = K_train.toarray().astype('float')\n",
    "    \n",
    "    K_val = D_val.dot(D_train.transpose())\n",
    "    K_val = K_val.toarray().astype('float')\n",
    "    \n",
    "    K_test = D_test.dot(D_train.transpose())\n",
    "    K_test = K_test.toarray().astype('float')\n",
    "    \n",
    "        \n",
    "    return(K_train, K_val, K_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the spectrum-kernels for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_, Xval0_, ytr0, yval0 = train_test_split(Xtr0, Ytr0, test_size=0.5, random_state=42)\n",
    "Xtr1_, Xval1_, ytr1, yval1 = train_test_split(Xtr1, Ytr1, test_size=0.5, random_state=42)\n",
    "Xtr2_, Xval2_, ytr2, yval2 = train_test_split(Xtr2, Ytr2, test_size=0.5, random_state=42)\n",
    "\n",
    "Xte0 = features_into_array(\"data/Xte0.csv\")\n",
    "Xte1 = features_into_array(\"data/Xte1.csv\")\n",
    "Xte2 = features_into_array(\"data/Xte2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 0.054116010665893555 seconds ---\n",
      "--- Computed kernel in 1.334479808807373 seconds ---\n",
      "--- Computed kernel in 1.1869618892669678 seconds ---\n",
      "--- Computed kernel in 1.1559290885925293 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "start_time = time.time()\n",
    "alphabet_8 = all_possible_substrings(k)\n",
    "print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "\n",
    "K_tr0, K_val0, K_te0 = spectrum_kernel(Xtr0_, Xval0_, Xte0, k, alphabet=alphabet_8,)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "K_tr1, K_val1, K_te1 = spectrum_kernel(Xtr1_, Xval1_, Xte1, k, alphabet=alphabet_8)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "K_tr2, K_val2, K_te2 = spectrum_kernel(Xtr2_, Xval2_, Xte2, k, alphabet=alphabet_8)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-Validation\n",
    "(runs to make sure everything is ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* KRR for dataset 0*************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 502.1897, accuracy = 1.000000\n",
      "Validation: loss = 436.9339, accuracy = 0.583000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 502.1897, accuracy = 1.000000\n",
      "Validation: loss = 436.9339, accuracy = 0.583000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 502.1897, accuracy = 1.000000\n",
      "Validation: loss = 436.9339, accuracy = 0.583000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 502.1896, accuracy = 1.000000\n",
      "Validation: loss = 436.9338, accuracy = 0.583000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 502.1888, accuracy = 1.000000\n",
      "Validation: loss = 436.9328, accuracy = 0.583000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 502.1803, accuracy = 1.000000\n",
      "Validation: loss = 436.9220, accuracy = 0.583000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 502.0951, accuracy = 1.000000\n",
      "Validation: loss = 436.8145, accuracy = 0.583000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 501.2490, accuracy = 1.000000\n",
      "Validation: loss = 435.7496, accuracy = 0.583000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 493.2875, accuracy = 1.000000\n",
      "Validation: loss = 426.0175, accuracy = 0.588000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 441.2574, accuracy = 1.000000\n",
      "Validation: loss = 372.7022, accuracy = 0.586000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 321.2479, accuracy = 0.984000\n",
      "Validation: loss = 292.5258, accuracy = 0.597000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 268.8207, accuracy = 0.577000\n",
      "Validation: loss = 278.1435, accuracy = 0.511000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 364.5540, accuracy = 0.535000\n",
      "Validation: loss = 391.3909, accuracy = 0.503000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 504.2911, accuracy = 1.000000\n",
      "Validation: loss = 432.6972, accuracy = 0.577000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 504.2911, accuracy = 1.000000\n",
      "Validation: loss = 432.6972, accuracy = 0.577000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 504.2911, accuracy = 1.000000\n",
      "Validation: loss = 432.6972, accuracy = 0.577000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 504.2910, accuracy = 1.000000\n",
      "Validation: loss = 432.6971, accuracy = 0.577000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 504.2902, accuracy = 1.000000\n",
      "Validation: loss = 432.6961, accuracy = 0.577000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 504.2821, accuracy = 1.000000\n",
      "Validation: loss = 432.6867, accuracy = 0.577000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 504.2007, accuracy = 1.000000\n",
      "Validation: loss = 432.5923, accuracy = 0.577000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 503.3910, accuracy = 1.000000\n",
      "Validation: loss = 431.6551, accuracy = 0.578000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 495.6890, accuracy = 1.000000\n",
      "Validation: loss = 422.8852, accuracy = 0.578000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 443.1289, accuracy = 1.000000\n",
      "Validation: loss = 369.7262, accuracy = 0.590000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 319.7368, accuracy = 0.987000\n",
      "Validation: loss = 285.4557, accuracy = 0.606000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 268.8625, accuracy = 0.576000\n",
      "Validation: loss = 272.5141, accuracy = 0.504000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 380.5827, accuracy = 0.509000\n",
      "Validation: loss = 396.3860, accuracy = 0.490000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 80299.2102, accuracy = 0.560000\n",
      "Validation: loss = 68251.7132, accuracy = 0.557000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 503.8617, accuracy = 1.000000\n",
      "Validation: loss = 441.0559, accuracy = 0.686000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 503.8617, accuracy = 1.000000\n",
      "Validation: loss = 441.0559, accuracy = 0.686000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 503.8616, accuracy = 1.000000\n",
      "Validation: loss = 441.0558, accuracy = 0.686000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 503.8609, accuracy = 1.000000\n",
      "Validation: loss = 441.0549, accuracy = 0.686000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 503.8538, accuracy = 1.000000\n",
      "Validation: loss = 441.0456, accuracy = 0.686000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 503.7829, accuracy = 1.000000\n",
      "Validation: loss = 440.9534, accuracy = 0.686000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 503.0794, accuracy = 1.000000\n",
      "Validation: loss = 440.0523, accuracy = 0.686000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 496.4818, accuracy = 1.000000\n",
      "Validation: loss = 432.2169, accuracy = 0.693000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 452.6180, accuracy = 1.000000\n",
      "Validation: loss = 390.2756, accuracy = 0.697000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 342.8970, accuracy = 0.986000\n",
      "Validation: loss = 317.1006, accuracy = 0.716000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 278.4063, accuracy = 0.684000\n",
      "Validation: loss = 280.7759, accuracy = 0.594000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 379.6870, accuracy = 0.499000\n",
      "Validation: loss = 380.5138, accuracy = 0.504000\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "\n",
    "print(\"************* KRR for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KRR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = KRR(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = KRR(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************KLR for dataset 0*************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3157, accuracy = 1.000000\n",
      "Validation: loss = 0.6977, accuracy = 0.581000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3340, accuracy = 1.000000\n",
      "Validation: loss = 0.6853, accuracy = 0.583000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.4236, accuracy = 0.996000\n",
      "Validation: loss = 0.6581, accuracy = 0.605000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.5839, accuracy = 0.925000\n",
      "Validation: loss = 0.6577, accuracy = 0.604000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6700, accuracy = 0.788000\n",
      "Validation: loss = 0.6813, accuracy = 0.569000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3156, accuracy = 1.000000\n",
      "Validation: loss = 0.6967, accuracy = 0.581000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3338, accuracy = 1.000000\n",
      "Validation: loss = 0.6831, accuracy = 0.583000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.4259, accuracy = 1.000000\n",
      "Validation: loss = 0.6566, accuracy = 0.623000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.5924, accuracy = 0.946000\n",
      "Validation: loss = 0.6688, accuracy = 0.623000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6768, accuracy = 0.872000\n",
      "Validation: loss = 0.6883, accuracy = 0.619000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3153, accuracy = 1.000000\n",
      "Validation: loss = 0.5949, accuracy = 0.695000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3305, accuracy = 1.000000\n",
      "Validation: loss = 0.5894, accuracy = 0.692000\n",
      "0.01 10\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.4078, accuracy = 0.998000\n",
      "Validation: loss = 0.5871, accuracy = 0.713000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.5609, accuracy = 0.926000\n",
      "Validation: loss = 0.6195, accuracy = 0.726000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6625, accuracy = 0.841000\n",
      "Validation: loss = 0.6700, accuracy = 0.694000\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-4,1)]\n",
    "\n",
    "print(\"*************KLR for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KLR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas, tresh=1e-8)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = KLR(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas, tresh=1e-8)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = KLR(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas, tresh= 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.893657, accuracy = 0.601000\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.893657, accuracy = 0.601000\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.011567, accuracy = 0.996000\n",
      "Validation: loss = 0.882224, accuracy = 0.594000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.453866, accuracy = 0.907000\n",
      "Validation: loss = 0.830064, accuracy = 0.615000\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.878176, accuracy = 0.622000\n",
      "Validation: loss = 0.931827, accuracy = 0.520000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.987214, accuracy = 0.613000\n",
      "Validation: loss = 0.992732, accuracy = 0.521000\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.998721, accuracy = 0.612000\n",
      "Validation: loss = 0.999273, accuracy = 0.520000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.883122, accuracy = 0.593000\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.883121, accuracy = 0.593000\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.004027, accuracy = 1.000000\n",
      "Validation: loss = 0.881896, accuracy = 0.593000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.465936, accuracy = 0.905000\n",
      "Validation: loss = 0.865339, accuracy = 0.623000\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.928599, accuracy = 0.849000\n",
      "Validation: loss = 0.978209, accuracy = 0.606000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.992766, accuracy = 0.845000\n",
      "Validation: loss = 0.997767, accuracy = 0.605000\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.999277, accuracy = 0.846000\n",
      "Validation: loss = 0.999777, accuracy = 0.605000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.684597, accuracy = 0.699000\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.684595, accuracy = 0.699000\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.004626, accuracy = 0.998000\n",
      "Validation: loss = 0.682209, accuracy = 0.692000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.383208, accuracy = 0.909000\n",
      "Validation: loss = 0.685569, accuracy = 0.723000\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.843474, accuracy = 0.819000\n",
      "Validation: loss = 0.873048, accuracy = 0.689000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.984237, accuracy = 0.820000\n",
      "Validation: loss = 0.987183, accuracy = 0.689000\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.998424, accuracy = 0.821000\n",
      "Validation: loss = 0.998718, accuracy = 0.689000\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-4, 3)]\n",
    "print(\"************* SVM for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = SVM(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = SVM(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernels = [K_te0, K_te1, K_te2]\n",
    "#test_alphas = [alphas_tr0[-4], alphas_tr1[-4], alphas_tr2[-3]] # il faut choisir l'alpha associé à un bon lambda!\n",
    "test_alphas = [alphas_tr0[0], alphas_tr1[0], alphas_tr2[0]]\n",
    "write_predictions_csv(test_kernels, test_alphas, path =\"data/Ytest_sequences.csv\", mode=\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
