{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "engaging-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from classifiers import *\n",
    "from metrics import *\n",
    "from kernels import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split # lui il va partir mais pour l'instant c'est pratique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vital-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_mat100 = np.genfromtxt(\"data/Xtr0_mat100.csv\", delimiter='')\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1_mat100 = np.genfromtxt(\"data/Xtr1_mat100.csv\", delimiter='')\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2_mat100 = np.genfromtxt(\"data/Xtr2_mat100.csv\", delimiter='')\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stable-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0, Xval0, ytr0, yval0 = train_test_split(Xtr0_mat100, Ytr0, test_size=0.5, random_state=42)\n",
    "Xtr1, Xval1, ytr1, yval1 = train_test_split(Xtr1_mat100, Ytr1, test_size=0.5, random_state=42)\n",
    "Xtr2, Xval2, ytr2, yval2 = train_test_split(Xtr2_mat100, Ytr2, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-vessel",
   "metadata": {},
   "source": [
    "## Create the kernel matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "capital-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0_ln, K_val0_ln = linear_kernel(Xtr0, Xval0)\n",
    "K_tr1_ln, K_val1_ln = linear_kernel(Xtr1, Xval1)\n",
    "K_tr2_ln, K_val2_ln = linear_kernel(Xtr2, Xval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reverse-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0, K_val0 = gaussian_kernel(Xtr0, Xval0)\n",
    "K_tr1, K_val1 = gaussian_kernel(Xtr1, Xval1)\n",
    "K_tr2, K_val2 = gaussian_kernel(Xtr2, Xval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "toxic-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0_poly, K_val0_poly = polynomial_kernel(Xtr0, Xval0, d=3, c=1)\n",
    "K_tr1_poly, K_val1_poly = polynomial_kernel(Xtr1, Xval1, d=3, c=1)\n",
    "K_tr2_poly, K_val2_poly = polynomial_kernel(Xtr2, Xval2, d=3, c=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-dispute",
   "metadata": {},
   "source": [
    "## We test only one kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adopted-seating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* KRR for dataset 0*************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 497.5500, accuracy = 1.000000\n",
      "Validation: loss = 310.6197, accuracy = 0.570000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 497.5499, accuracy = 1.000000\n",
      "Validation: loss = 310.6197, accuracy = 0.570000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 497.5491, accuracy = 1.000000\n",
      "Validation: loss = 310.6196, accuracy = 0.570000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 497.5411, accuracy = 1.000000\n",
      "Validation: loss = 310.6186, accuracy = 0.570000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 497.4610, accuracy = 1.000000\n",
      "Validation: loss = 310.6092, accuracy = 0.570000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 496.6629, accuracy = 1.000000\n",
      "Validation: loss = 310.5155, accuracy = 0.570000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 488.9667, accuracy = 1.000000\n",
      "Validation: loss = 309.6093, accuracy = 0.573000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 432.4610, accuracy = 1.000000\n",
      "Validation: loss = 302.7290, accuracy = 0.581000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 306.7846, accuracy = 0.977000\n",
      "Validation: loss = 282.1138, accuracy = 0.584000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 263.4305, accuracy = 0.687000\n",
      "Validation: loss = 267.3457, accuracy = 0.551000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 288.7743, accuracy = 0.535000\n",
      "Validation: loss = 303.0325, accuracy = 0.503000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 411.5986, accuracy = 0.535000\n",
      "Validation: loss = 439.5511, accuracy = 0.503000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 458.4916, accuracy = 0.535000\n",
      "Validation: loss = 490.0275, accuracy = 0.503000\n",
      "************* KRR for dataset 1*************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 499.8380, accuracy = 1.000000\n",
      "Validation: loss = 304.1439, accuracy = 0.577000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 499.8379, accuracy = 1.000000\n",
      "Validation: loss = 304.1438, accuracy = 0.577000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 499.8370, accuracy = 1.000000\n",
      "Validation: loss = 304.1437, accuracy = 0.577000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 499.8283, accuracy = 1.000000\n",
      "Validation: loss = 304.1427, accuracy = 0.577000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 499.7408, accuracy = 1.000000\n",
      "Validation: loss = 304.1326, accuracy = 0.577000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 498.8694, accuracy = 1.000000\n",
      "Validation: loss = 304.0313, accuracy = 0.577000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 490.4755, accuracy = 1.000000\n",
      "Validation: loss = 303.0527, accuracy = 0.578000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 429.6232, accuracy = 1.000000\n",
      "Validation: loss = 295.7302, accuracy = 0.586000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 301.8628, accuracy = 0.968000\n",
      "Validation: loss = 276.2306, accuracy = 0.578000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 264.4813, accuracy = 0.660000\n",
      "Validation: loss = 264.9076, accuracy = 0.555000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 292.6725, accuracy = 0.509000\n",
      "Validation: loss = 300.3593, accuracy = 0.490000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 429.3003, accuracy = 0.509000\n",
      "Validation: loss = 445.9723, accuracy = 0.490000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 483.4250, accuracy = 0.509000\n",
      "Validation: loss = 502.1660, accuracy = 0.490000\n",
      "************* KRR for dataset 2*************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 7082.5980, accuracy = 0.616000\n",
      "Validation: loss = 6290.9359, accuracy = 0.552000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 499.9979, accuracy = 1.000000\n",
      "Validation: loss = 345.2061, accuracy = 0.677000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 499.9972, accuracy = 1.000000\n",
      "Validation: loss = 345.2060, accuracy = 0.677000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 499.9904, accuracy = 1.000000\n",
      "Validation: loss = 345.2051, accuracy = 0.677000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 499.9218, accuracy = 1.000000\n",
      "Validation: loss = 345.1958, accuracy = 0.677000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 499.2381, accuracy = 1.000000\n",
      "Validation: loss = 345.1028, accuracy = 0.677000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 492.6360, accuracy = 1.000000\n",
      "Validation: loss = 344.1805, accuracy = 0.679000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 443.6214, accuracy = 1.000000\n",
      "Validation: loss = 336.8586, accuracy = 0.680000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 330.2627, accuracy = 0.969000\n",
      "Validation: loss = 312.3465, accuracy = 0.687000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 275.0285, accuracy = 0.731000\n",
      "Validation: loss = 275.9335, accuracy = 0.652000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 297.7531, accuracy = 0.499000\n",
      "Validation: loss = 295.8680, accuracy = 0.504000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 440.7353, accuracy = 0.499000\n",
      "Validation: loss = 436.2669, accuracy = 0.504000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 493.7018, accuracy = 0.499000\n",
      "Validation: loss = 488.7577, accuracy = 0.504000\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "print(\"************* KRR for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KRR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print(\"************* KRR for dataset 1*************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = KRR(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas)\n",
    "print(\"************* KRR for dataset 2*************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = KRR(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-article",
   "metadata": {},
   "source": [
    "## example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thorough-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte0 = np.genfromtxt(\"data/Xte0_mat100.csv\", delimiter='')\n",
    "Xte1 = np.genfromtxt(\"data/Xte1_mat100.csv\", delimiter='')\n",
    "Xte2 = np.genfromtxt(\"data/Xte2_mat100.csv\", delimiter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "contrary-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_te0 = gaussian_kernel(Xtr0, Xte0, mode=\"test\")\n",
    "K_te1 = gaussian_kernel(Xtr1, Xte1, mode=\"test\")\n",
    "K_te2 = gaussian_kernel(Xtr2, Xte2, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alone-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving predictions\n",
      "saved predictions\n"
     ]
    }
   ],
   "source": [
    "test_kernels = [K_te0, K_te1, K_te2]\n",
    "#test_alphas = [alphas_tr0[-4], alphas_tr1[-4], alphas_tr2[-3]] # il faut choisir l'alpha associé à un bon lambda!\n",
    "test_alphas = [alphas_tr0[0], alphas_tr1[0], alphas_tr2[0]]\n",
    "write_predictions_csv(test_kernels, test_alphas, path =\"data/Ytest_KLR.csv\", mode=\"KRR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-father",
   "metadata": {},
   "source": [
    "# Testing the accuracy on sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "closed-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "def features_into_array(path):\n",
    "    with open(path, 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        X = list()\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                # row variable is a list that represents a row in csv\n",
    "                X.append(np.array(row[1]))\n",
    "                \n",
    "    X = np.array(X) ## dtype might be changed in something more convenient. For now, dtype = \"<U1\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equivalent-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_seq = features_into_array(\"data/Xtr0.csv\")\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1_seq = features_into_array(\"data/Xtr1.csv\")\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2_seq = features_into_array(\"data/Xtr2.csv\")\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0, Xval0, ytr0, yval0 = train_test_split(Xtr0_seq, Ytr0, test_size=0.5, random_state=42)\n",
    "Xtr1, Xval1, ytr1, yval1 = train_test_split(Xtr1_seq, Ytr1, test_size=0.5, random_state=42)\n",
    "Xtr2, Xval2, ytr2, yval2 = train_test_split(Xtr2_seq, Ytr2, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-mitchell",
   "metadata": {},
   "source": [
    "## Predictions on the testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte0_seq = features_into_array(\"data/Xte0.csv\")\n",
    "Xte1_seq = features_into_array(\"data/Xte1.csv\")\n",
    "Xte2_seq = features_into_array(\"data/Xte2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
