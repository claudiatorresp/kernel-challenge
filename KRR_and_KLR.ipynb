{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "utility-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-pattern",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-chosen",
   "metadata": {},
   "source": [
    "For $k = 0, 1, 2$ we have the following files:\n",
    "* Xtrk.csv - the training sequences.\n",
    "* Xtek.csv - the test sequences.\n",
    "* Ytrk.csv - labels for the training sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "given-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_mat100 = np.genfromtxt(\"data/Xtr0_mat100.csv\", delimiter='')\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1_mat100 = np.genfromtxt(\"data/Xtr1_mat100.csv\", delimiter='')\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2_mat100 = np.genfromtxt(\"data/Xtr2_mat100.csv\", delimiter='')\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "running-alert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr0_mat100.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-impossible",
   "metadata": {},
   "source": [
    "# Implementing some kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-nature",
   "metadata": {},
   "source": [
    "## Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bottom-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x,y, sigma):\n",
    "    exp_term = np.linalg.norm(x-y)**2 /(2*sigma)\n",
    "    return(np.exp(-exp_term))\n",
    "\n",
    "# Naive computation of the gaussian kernel that can be easily improved\n",
    "def gaussian_kernel(X,sigma):\n",
    "    n = X.shape[0]\n",
    "    K = np.eye(n) # One along the diagonals because K(x,x) = exp(0) = 1\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            val = gaussian(X[i], X[j], sigma)\n",
    "            K[i,j] = val\n",
    "            K[j,i] = val\n",
    "    return(K)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-yemen",
   "metadata": {},
   "source": [
    "## Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-harbor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "recognized-attachment",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-rough",
   "metadata": {},
   "source": [
    "* Consider RKHS $\\mathcal H$, associated to a p.d. kernel K on $\\mathcal X$\n",
    "* Let $y = (y_1, \\dots, y_n)^T \\in \\mathbb R ^n$\n",
    "* Let $\\alpha = (\\alpha_1, \\dots, \\alpha_n)^T \\in \\mathbb R ^n$\n",
    "* Let $K$ be the $n\\times n$ Gram Matrix such that $K_{i,j} = K(x_i, x_j)$\n",
    "* We can then write\n",
    "$$\n",
    "(\\hat f(x_1), \\dots, \\hat f(x_n))^T = K\\alpha\n",
    "$$\n",
    "* The norm is $||\\hat f||^2_{\\mathcal H} = \\alpha^T K \\alpha$\n",
    "* KRR $\\leftrightarrow \\text{argmin}_{\\alpha \\in \\mathbb R^n} \\frac{1}{n} (K\\alpha - y)^T(K\\alpha - y) + \\lambda \\alpha^T K \\alpha$\n",
    "* Solution for $\\lambda > 0$:\n",
    "$$\n",
    "\\alpha = (K+\\lambda nI)^{-1}y\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "biological-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KRR(X, y, lambd, kernel = \"gaussian\", sigma=0.5 ):\n",
    "    \"\"\"\n",
    "    make lambd a list so we can test multiple regularisations without having to compute the kernel multiple times\n",
    "    returns the predictions for each value of lambd\n",
    "    \"\"\"\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    assert len(lambd) > 0\n",
    "    \n",
    "    # Compute the kernel matrix for our data\n",
    "    if kernel==\"gaussian\":\n",
    "        K = gaussian_kernel(X, sigma)\n",
    "    y_preds = []\n",
    "    loss = []\n",
    "    for l in lambd:\n",
    "        assert l >= 0\n",
    "        # find the parameter alpha\n",
    "        alpha = np.linalg.solve((K + l*n*np.eye(n)), y)\n",
    "        # predict\n",
    "        loss_lambda = MSE(y, l, alpha, K)\n",
    "        print(f\"The MSE for the chosen parameters (lambda = {l:.2f} and sigma = {sigma:.2f}) is : {loss_lambda:.4f}\")\n",
    "        y_preds += [K @ alpha]\n",
    "        loss += [loss_lambda]\n",
    "    return(y_preds, loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "wound-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, lambd, alpha, K):\n",
    "    n = y.shape[0]\n",
    "    data_term = (np.linalg.norm(np.dot(K, alpha.reshape(-1,1)) - y)**2)/n\n",
    "    reg_term = alpha @ K @ alpha\n",
    "    return(data_term + lambd * reg_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "gorgeous-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the chosen parameters (lambda = 0.00 and sigma = 0.50) is : 998.5560\n",
      "The MSE for the chosen parameters (lambda = 0.10 and sigma = 0.50) is : 503.3328\n",
      "The MSE for the chosen parameters (lambda = 0.20 and sigma = 0.50) is : 512.7811\n",
      "The MSE for the chosen parameters (lambda = 0.30 and sigma = 0.50) is : 525.0479\n",
      "The MSE for the chosen parameters (lambda = 0.40 and sigma = 0.50) is : 538.6433\n",
      "The MSE for the chosen parameters (lambda = 0.50 and sigma = 0.50) is : 552.7041\n",
      "The MSE for the chosen parameters (lambda = 1.00 and sigma = 0.50) is : 618.3160\n",
      "The MSE for the chosen parameters (lambda = 1.50 and sigma = 0.50) is : 669.7054\n",
      "The MSE for the chosen parameters (lambda = 2.00 and sigma = 0.50) is : 708.8776\n",
      "The MSE for the chosen parameters (lambda = 2.50 and sigma = 0.50) is : 739.2341\n",
      "The MSE for the chosen parameters (lambda = 3.00 and sigma = 0.50) is : 763.2896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([-1.01863407e-10,  9.99999999e-01,  1.00000000e+00, ...,\n",
       "         -2.18278728e-10, -5.96628524e-10, -2.32830644e-10]),\n",
       "  array([0.43943344, 0.4340629 , 0.4323965 , ..., 0.43665257, 0.43673756,\n",
       "         0.43516752]),\n",
       "  array([0.40155027, 0.39691609, 0.39560559, ..., 0.39893663, 0.39962271,\n",
       "         0.39869787]),\n",
       "  array([0.36985701, 0.36567165, 0.3645303 , ..., 0.36742687, 0.36824697,\n",
       "         0.36755341]),\n",
       "  array([0.34283881, 0.33899753, 0.33797011, ..., 0.34057553, 0.34142318,\n",
       "         0.34085396]),\n",
       "  array([0.31951253, 0.31595399, 0.3150136 , ..., 0.31739725, 0.3182362 ,\n",
       "         0.317747  ]),\n",
       "  array([0.23844113, 0.23581735, 0.23514116, ..., 0.23685358, 0.23755287,\n",
       "         0.23724959]),\n",
       "  array([0.19019411, 0.18810968, 0.18757713, ..., 0.18892539, 0.18950268,\n",
       "         0.18927723]),\n",
       "  array([0.15818779, 0.15645765, 0.15601755, ..., 0.15713157, 0.15761983,\n",
       "         0.15743917]),\n",
       "  array([0.1354025 , 0.13392336, 0.13354812, ..., 0.1344979 , 0.13492   ,\n",
       "         0.13476888]),\n",
       "  array([0.11835492, 0.11706306, 0.11673591, ..., 0.11756392, 0.1179353 ,\n",
       "         0.11780526])],\n",
       " [998.5560000024693,\n",
       "  503.3328038166729,\n",
       "  512.781088059742,\n",
       "  525.0479016266605,\n",
       "  538.6432926205351,\n",
       "  552.7040739403902,\n",
       "  618.315974168215,\n",
       "  669.7053995758099,\n",
       "  708.8776419738957,\n",
       "  739.2340649936118,\n",
       "  763.2895583095976])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR(Xtr0_mat100, Ytr0[:,1], [0, 0.1, 0.2,0.3,0.4, 0.5,1,1.5,2,2.5,3], sigma = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-twenty",
   "metadata": {},
   "source": [
    "## Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-creator",
   "metadata": {},
   "source": [
    "- Binary Classificaiton setup: $\\mathcal Y = \\{-1, 1\\}$\n",
    "- $\\mathcal l_{0/1}(f(x),y) = \\mathbb 1\\{yf(x) < 0 \\}$ (0 if $y = \\text{sign}f(x)$, 1 otherwise)\n",
    "- $\\mathcal l_{\\text{logistic}}(f(x),y) = -\\log p(y|f(x)) = \\log(1 + e^{-yf(x)})$ where $p(y|f(x)) = \\sigma(y(f(x))$\n",
    "- solve WKRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-conflict",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
