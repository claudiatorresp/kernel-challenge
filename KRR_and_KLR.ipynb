{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "utility-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-conducting",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-strip",
   "metadata": {},
   "source": [
    "For $k = 0, 1, 2$ we have the following files:\n",
    "* Xtrk.csv - the training sequences.\n",
    "* Xtek.csv - the test sequences.\n",
    "* Ytrk.csv - labels for the training sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "academic-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_mat100 = np.genfromtxt(\"data/Xtr0_mat100.csv\", delimiter='')\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1_mat100 = np.genfromtxt(\"data/Xtr1_mat100.csv\", delimiter='')\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2_mat100 = np.genfromtxt(\"data/Xtr2_mat100.csv\", delimiter='')\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "radical-reading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytr2[:,1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "extreme-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true,y_pred):\n",
    "    n = y_true.shape[0]\n",
    "    predictions = np.zeros(n)\n",
    "    predictions[y_pred >= 0.5] = 1\n",
    "    return np.sum(y_true == predictions) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-history",
   "metadata": {},
   "source": [
    "# Implementing some kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-trinity",
   "metadata": {},
   "source": [
    "## Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "judicial-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(X):\n",
    "    return(X @ X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-saying",
   "metadata": {},
   "source": [
    "## Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "located-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x,y, sigma):\n",
    "    exp_term = np.linalg.norm(x-y)**2 /(2*sigma)\n",
    "    return(np.exp(-exp_term))\n",
    "\n",
    "# Naive computation of the gaussian kernel that can be easily improved\n",
    "def gaussian_kernel(X,sigma):\n",
    "    n = X.shape[0]\n",
    "    K = np.eye(n) # One along the diagonals because K(x,x) = exp(0) = 1\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            val = gaussian(X[i], X[j], sigma)\n",
    "            K[i,j] = val\n",
    "            K[j,i] = val\n",
    "    return(K)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-policy",
   "metadata": {},
   "source": [
    "## Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "young-nigeria",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-preservation",
   "metadata": {},
   "source": [
    "* Consider RKHS $\\mathcal H$, associated to a p.d. kernel K on $\\mathcal X$\n",
    "* Let $y = (y_1, \\dots, y_n)^T \\in \\mathbb R ^n$\n",
    "* Let $\\alpha = (\\alpha_1, \\dots, \\alpha_n)^T \\in \\mathbb R ^n$\n",
    "* Let $K$ be the $n\\times n$ Gram Matrix such that $K_{i,j} = K(x_i, x_j)$\n",
    "* We can then write\n",
    "$$\n",
    "(\\hat f(x_1), \\dots, \\hat f(x_n))^T = K\\alpha\n",
    "$$\n",
    "* The norm is $||\\hat f||^2_{\\mathcal H} = \\alpha^T K \\alpha$\n",
    "* KRR $\\leftrightarrow \\text{argmin}_{\\alpha \\in \\mathbb R^n} \\frac{1}{n} (K\\alpha - y)^T(K\\alpha - y) + \\lambda \\alpha^T K \\alpha$\n",
    "* Solution for $\\lambda > 0$:\n",
    "$$\n",
    "\\alpha = (K+\\lambda nI)^{-1}y\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "smoking-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KRR(K, y, lambd):\n",
    "    \"\"\"\n",
    "    takes the kernel matrix as an input and computes the MSE and the predictions for each value in lambd (list)\n",
    "    \"\"\"\n",
    "    assert K.shape[0] == y.shape[0]\n",
    "    assert len(lambd) > 0\n",
    "    \n",
    "    y_preds = []\n",
    "    loss = []\n",
    "    accuracies = []\n",
    "    alphas = []\n",
    "    for l in lambd:\n",
    "        assert l >= 0\n",
    "        # find the parameter alpha\n",
    "        alpha = np.linalg.solve((K + l*n*np.eye(n)), y)\n",
    "        # predict\n",
    "        loss_lambda = MSE(K, y, l, alpha)\n",
    "        accuracy_lambda = accuracy(y,K@alpha)\n",
    "        print(f\"The MSE  and accuracy for lambda = {l} are : {loss_lambda:.4f}, {accuracy_lambda:.6f} \")\n",
    "        y_preds += [K @ alpha]\n",
    "        loss += [loss_lambda]\n",
    "        accuracies += [accuracy_lambda]\n",
    "        alphas +=[alpha]\n",
    "        \n",
    "    return(y_preds, alphas, loss, accuracies)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "diverse-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(K, y, lambd, alpha):\n",
    "    n = y.shape[0]\n",
    "    data_term = (np.linalg.norm(np.dot(K, alpha.reshape(-1,1)) - y)**2)/n\n",
    "    reg_term = alpha @ K @ alpha\n",
    "    return(data_term + lambd * reg_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "marine-hardware",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "K_tr0 = gaussian_kernel(Xtr0_mat100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "compliant-distribution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE  and accuracy for lambda = 0 are : 998.5560, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-10 are : 991.7629, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-09 are : 943.8538, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-08 are : 775.9972, 0.995500 \n",
      "The MSE  and accuracy for lambda = 1e-07 are : 614.2858, 0.866000 \n",
      "The MSE  and accuracy for lambda = 1e-06 are : 567.3305, 0.706000 \n",
      "The MSE  and accuracy for lambda = 1e-05 are : 554.5332, 0.656000 \n",
      "The MSE  and accuracy for lambda = 0.0001 are : 523.9276, 0.637000 \n",
      "The MSE  and accuracy for lambda = 0.001 are : 501.4996, 0.607500 \n",
      "The MSE  and accuracy for lambda = 0.01 are : 499.3773, 0.519000 \n",
      "The MSE  and accuracy for lambda = 0.1 are : 503.2188, 0.519000 \n",
      "The MSE  and accuracy for lambda = 1 are : 616.6589, 0.519000 \n",
      "The MSE  and accuracy for lambda = 10 are : 882.6979, 0.519000 \n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "pred_tr0, alphas_tr0, loss_tr0, accuracies = KRR(K_tr0, Ytr0[:,1], lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-genius",
   "metadata": {},
   "source": [
    "## Kernel Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-charity",
   "metadata": {},
   "source": [
    "- Binary Classificaiton setup: $\\mathcal Y = \\{-1, 1\\}$\n",
    "- $\\mathcal l_{\\text{logistic}}(f(x),y) = -\\log p(y|f(x)) = \\log(1 + e^{-yf(x)})$ where $p(y|f(x)) = \\sigma(y(f(x))$\n",
    "\n",
    "Objective:\n",
    "\\begin{align*}\n",
    "\\hat f &= \\text{argmin}_{f\\in \\mathcal H} \\frac{1}{n} \\sum_{i=1}^n \\log(1+e^{-y_if(x_i)}) + \\frac{\\lambda}{2}||f||^2_{\\mathcal H}\\\\\n",
    "\\alpha &= \\text{argmin}_{\\alpha \\in \\mathbb R^n} \\frac{1}{n} \\sum_{i=1}^n \\log(1+e^{-y_i[K\\alpha]_i}) + \\frac{\\lambda}{2} \\alpha^T K \\alpha\n",
    "\\end{align*}\n",
    "\n",
    "We define the following fonctions and vectors:\n",
    "* $\\mathcal l _\\text{logistic}(u) = \\log(1+e^{-u})$\n",
    "* $\\mathcal l' _\\text{logistic}(u) = -\\sigma(-u)$\n",
    "* $\\mathcal l'' _\\text{logistic}(u) = \\sigma(u)\\sigma(-u)$\n",
    "\n",
    "* for $i = 1, \\dots, n$, $P_i(\\alpha) = \\mathcal l' _\\text{logistic}(y_i[K\\alpha]_i)$\n",
    "* for $i = 1, \\dots, n$, $W_i(\\alpha) = \\mathcal l'' _\\text{logistic}(y_i[K\\alpha]_i)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "J(\\alpha) &= \\frac{1}{n} \\sum_{i=1}^n \\log(1+e^{-y_i[K\\alpha]_i}) + \\frac{\\lambda}{2} \\alpha^T K \\alpha\\\\\n",
    "\\nabla J(\\alpha) &= \\frac{1}{n} KP(\\alpha) y + \\lambda K \\alpha \\quad \\text{where } P(\\alpha) = \\text{diag}(P_1(\\alpha), \\dots, P_n(\\alpha))\\\\\n",
    "\\nabla^2 J(\\alpha) &= \\frac{1}{n}KW(\\alpha)K+\\lambda K \\quad \\text{where } W(\\alpha) = \\text{diag}(W_1(\\alpha), \\dots, W_n(\\alpha))\n",
    "\\end{align*}\n",
    "\n",
    "We are interested in the quadratic approximation of $J$ near a point $\\alpha_0$:\n",
    "\\begin{align*}\n",
    "J_q(\\alpha) &= J(\\alpha_0) + (\\alpha - \\alpha_0)^T \\nabla J(\\alpha_0) + \\frac{1}{2} (\\alpha - \\alpha_0)^T \\nabla^2 J(\\alpha_0)(\\alpha - \\alpha_0)\\\\\n",
    "2J_q(\\alpha) &= -\\frac{2}{n} \\alpha^T KW(K\\alpha_0-W^{-1}Py)+\\frac{1}{n}\\alpha^TKWK\\alpha+ \\lambda\\alpha^TK\\alpha +C\\\\\n",
    "&= \\frac{1}{n} (K\\alpha - z)^TW(K\\alpha - z) + \\lambda\\alpha^TK\\alpha + C \\quad \\text{where} z = K\\alpha_0 - W^{-1} P y\n",
    "\\end{align*}\n",
    "\n",
    "The WKRR problem is presented as:\n",
    "$$\n",
    "\\text{argmin}_{\\alpha \\in \\mathbb R^n} \\frac{1}{n}(K\\alpha - y)^TW(K\\alpha - y) + \\lambda \\alpha^TK\\alpha\n",
    "$$\n",
    "and has as :\n",
    "$$\n",
    "\\alpha = W^{1/2} (W^{1/2}KW^{1/2}+n\\lambda I)^{-1} W^{1/2}y\n",
    "$$\n",
    "\n",
    "So, in order to solve KRL, we use IRLS on a WKRR problem until convergence:\n",
    "$$\\alpha^{t+1} \\gets \\text{solveWKRR}(K, W^t, z^t)$$\n",
    "With the updates for $W^t$ and $z^t$ from $\\alpha^t$ are:\n",
    "- $m_i \\gets [K\\alpha^t]_i$\n",
    "- $P_i^t \\gets -\\sigma(-y_im_i)$\n",
    "- $W_i^t \\gets \\sigma(m_i)\\sigma(-m_i)$\n",
    "- $z_i^t \\gets m_i + y_i / \\sigma(-y_im_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "discrete-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveWKRR(K,W,z,y,lambd):\n",
    "    \n",
    "    assert np.all(W >= 0)\n",
    "    \n",
    "    W_sq = np.sqrt(W)\n",
    "    n = K.shape[0]\n",
    "    inv_matrix = np.linalg.solve((W_sq @ K @ W_sq + n * lambd * np.eye(n)), W_sq @ y)\n",
    "    alpha = W_sq @ inv_matrix\n",
    "    \n",
    "    return alpha\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "governmental-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def logistic_loss(y_true, y_pred):\n",
    "    n = y_true.shape[0]\n",
    "    log_term = np.log(sigmoid(y_true*y_pred))\n",
    "    return(-np.sum(log_term)/n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "excellent-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLR(K, y, lambd, maxIter = 100, tresh = 1e-8):\n",
    "    \n",
    "    # initialize the values\n",
    "    assert K.shape[0] == y.shape[0]\n",
    "    n = K.shape[0]\n",
    "    \n",
    "    y_preds = []\n",
    "    loss = []\n",
    "    accuracies = []\n",
    "    alphas = []\n",
    "    \n",
    "    for l in lambd :\n",
    "        cnt = 0\n",
    "        \n",
    "        P_t, W_t = np.eye(n), np.eye(n)\n",
    "        z_t = K@ np.ones(n) - y\n",
    "        alpha_t = np.ones(n)\n",
    "        diff_alpha = np.inf\n",
    "\n",
    "\n",
    "        while (diff_alpha > tresh) and (cnt < maxIter):\n",
    "\n",
    "            old_alpha = alpha_t\n",
    "            alpha_t = solveWKRR(K, W_t, z_t, y, l)\n",
    "\n",
    "            m_t = K@alpha_t\n",
    "            sigma_m = sigmoid(m_t)\n",
    "            sigma_my = sigmoid(-y*m_t)\n",
    "\n",
    "            P_t = - np.diag(sigma_my)\n",
    "            W_t = np.diag(sigma_m * (1-sigma_m))\n",
    "\n",
    "            z_t = m_t - (P_t@y)/(sigma_m * (1-sigma_m))\n",
    "\n",
    "            diff_alpha = np.linalg.norm(alpha_t - old_alpha)\n",
    "            cnt+=1\n",
    "            if cnt % 10 == 0:\n",
    "                print(l, cnt)\n",
    "\n",
    "        pred_l = K@alpha_t\n",
    "        y_preds += [pred_l]\n",
    "        loss_l = logistic_loss(y, pred_l)\n",
    "        loss += [loss_l]\n",
    "        accuracy_l = accuracy(y, pred_l)\n",
    "        accuracies += [accuracy_l]\n",
    "        alphas +=[alpha_t]\n",
    "        print(f\"The logistic loss and accuracy for lambda = {l} are : {loss_l:.4f}, {accuracy_l:.6f} \")\n",
    "        \n",
    "    \n",
    "    return y_preds, alphas, loss, accuracies\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "olive-therapist",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "0 20\n",
      "0 30\n",
      "0 40\n",
      "0 50\n",
      "0 60\n",
      "0 70\n",
      "0 80\n",
      "0 90\n",
      "0 100\n",
      "The logistic loss and accuracy for lambda = 0 are : 0.5104, 1.000000 \n",
      "1e-10 10\n",
      "1e-10 20\n",
      "1e-10 30\n",
      "1e-10 40\n",
      "1e-10 50\n",
      "1e-10 60\n",
      "1e-10 70\n",
      "1e-10 80\n",
      "1e-10 90\n",
      "1e-10 100\n",
      "The logistic loss and accuracy for lambda = 1e-10 are : 0.5126, 1.000000 \n",
      "1e-09 10\n",
      "1e-09 20\n",
      "1e-09 30\n",
      "1e-09 40\n",
      "1e-09 50\n",
      "1e-09 60\n",
      "1e-09 70\n",
      "1e-09 80\n",
      "1e-09 90\n",
      "1e-09 100\n",
      "The logistic loss and accuracy for lambda = 1e-09 are : 0.5245, 0.998500 \n",
      "1e-08 10\n",
      "1e-08 20\n",
      "1e-08 30\n",
      "1e-08 40\n",
      "1e-08 50\n",
      "1e-08 60\n",
      "1e-08 70\n",
      "1e-08 80\n",
      "1e-08 90\n",
      "1e-08 100\n",
      "The logistic loss and accuracy for lambda = 1e-08 are : 0.5522, 0.941000 \n",
      "1e-07 10\n",
      "1e-07 20\n",
      "1e-07 30\n",
      "1e-07 40\n",
      "1e-07 50\n",
      "1e-07 60\n",
      "1e-07 70\n",
      "1e-07 80\n",
      "1e-07 90\n",
      "1e-07 100\n",
      "The logistic loss and accuracy for lambda = 1e-07 are : 0.5730, 0.746500 \n",
      "1e-06 10\n",
      "The logistic loss and accuracy for lambda = 1e-06 are : 0.5797, 0.665500 \n",
      "The logistic loss and accuracy for lambda = 1e-05 are : 0.5829, 0.648500 \n",
      "The logistic loss and accuracy for lambda = 0.0001 are : 0.5881, 0.618000 \n",
      "The logistic loss and accuracy for lambda = 0.001 are : 0.5911, 0.523000 \n",
      "The logistic loss and accuracy for lambda = 0.01 are : 0.5948, 0.519000 \n",
      "The logistic loss and accuracy for lambda = 0.1 are : 0.6184, 0.519000 \n",
      "The logistic loss and accuracy for lambda = 1 are : 0.6709, 0.519000 \n",
      "The logistic loss and accuracy for lambda = 10 are : 0.6904, 0.519000 \n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "preds = KLR(K_tr0, Ytr0[:,1], lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-software",
   "metadata": {},
   "source": [
    "# Testing the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-impossible",
   "metadata": {},
   "source": [
    "## Create the kernel matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "rotary-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0 = gaussian_kernel(Xtr0_mat100,1)\n",
    "K_tr1 = gaussian_kernel(Xtr1_mat100,1)\n",
    "K_tr2 = gaussian_kernel(Xtr2_mat100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-fever",
   "metadata": {},
   "source": [
    "## Testing KRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "completed-count",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************KRR for dataset 0*************\n",
      "\n",
      "The MSE  and accuracy for lambda = 0 are : 998.5560, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-10 are : 991.7629, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-09 are : 943.8538, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-08 are : 775.9972, 0.995500 \n",
      "The MSE  and accuracy for lambda = 1e-07 are : 614.2858, 0.866000 \n",
      "The MSE  and accuracy for lambda = 1e-06 are : 567.3305, 0.706000 \n",
      "The MSE  and accuracy for lambda = 1e-05 are : 554.5332, 0.656000 \n",
      "The MSE  and accuracy for lambda = 0.0001 are : 523.9276, 0.637000 \n",
      "The MSE  and accuracy for lambda = 0.001 are : 501.4996, 0.607500 \n",
      "The MSE  and accuracy for lambda = 0.01 are : 499.3773, 0.519000 \n",
      "The MSE  and accuracy for lambda = 0.1 are : 503.2188, 0.519000 \n",
      "The MSE  and accuracy for lambda = 1 are : 616.6589, 0.519000 \n",
      "The MSE  and accuracy for lambda = 10 are : 882.6979, 0.519000 \n",
      "*************KRR for dataset 1*************\n",
      "\n",
      "The MSE  and accuracy for lambda = 0 are : 999.9990, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-10 are : 992.8007, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-09 are : 942.1699, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-08 are : 770.8105, 0.995000 \n",
      "The MSE  and accuracy for lambda = 1e-07 are : 604.4490, 0.866500 \n",
      "The MSE  and accuracy for lambda = 1e-06 are : 554.7309, 0.695000 \n",
      "The MSE  and accuracy for lambda = 1e-05 are : 542.5005, 0.636000 \n",
      "The MSE  and accuracy for lambda = 0.0001 are : 516.3552, 0.622500 \n",
      "The MSE  and accuracy for lambda = 0.001 are : 501.5936, 0.608500 \n",
      "The MSE  and accuracy for lambda = 0.01 are : 500.1233, 0.539500 \n",
      "The MSE  and accuracy for lambda = 0.1 are : 504.2567, 0.499500 \n",
      "The MSE  and accuracy for lambda = 1 are : 627.0545, 0.499500 \n",
      "The MSE  and accuracy for lambda = 10 are : 915.1327, 0.499500 \n",
      "*************KRR for dataset 2*************\n",
      "\n",
      "The MSE  and accuracy for lambda = 0 are : 148222263415395.5000, 0.501500 \n",
      "The MSE  and accuracy for lambda = 1e-10 are : 994.7561, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-09 are : 957.1133, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-08 are : 817.2009, 1.000000 \n",
      "The MSE  and accuracy for lambda = 1e-07 are : 674.1257, 0.892000 \n",
      "The MSE  and accuracy for lambda = 1e-06 are : 635.1879, 0.765500 \n",
      "The MSE  and accuracy for lambda = 1e-05 are : 620.4356, 0.736000 \n",
      "The MSE  and accuracy for lambda = 0.0001 are : 570.9916, 0.714000 \n",
      "The MSE  and accuracy for lambda = 0.001 are : 510.0373, 0.686000 \n",
      "The MSE  and accuracy for lambda = 0.01 are : 500.2582, 0.641000 \n",
      "The MSE  and accuracy for lambda = 0.1 are : 504.2378, 0.501500 \n",
      "The MSE  and accuracy for lambda = 1 are : 626.0479, 0.501500 \n",
      "The MSE  and accuracy for lambda = 10 are : 911.7958, 0.501500 \n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "print(\"*************KRR for dataset 0*************\\n\")\n",
    "pred_tr0, alphas_tr0, loss_tr0, accuracies_0 = KRR(K_tr0, Ytr0[:,1], lambdas)\n",
    "print(\"*************KRR for dataset 1*************\\n\")\n",
    "pred_tr1, alphas_tr1, loss_tr1, accuracies_1 = KRR(K_tr1, Ytr1[:,1], lambdas)\n",
    "print(\"*************KRR for dataset 2*************\\n\")\n",
    "pred_tr2, alphas_tr2, loss_tr2, accuracies_2 = KRR(K_tr2, Ytr2[:,1], lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-terminology",
   "metadata": {},
   "source": [
    "## Testing KLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "tutorial-navigator",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************KLR for dataset 0*************\n",
      "\n",
      "0 10\n",
      "0 20\n",
      "0 30\n",
      "0 40\n",
      "0 50\n",
      "0 60\n",
      "0 70\n",
      "0 80\n",
      "0 90\n",
      "0 100\n",
      "The logistic loss and accuracy for lambda = 0 are : 0.5104, 1.000000 \n",
      "1e-10 10\n",
      "1e-10 20\n",
      "1e-10 30\n",
      "1e-10 40\n",
      "1e-10 50\n",
      "1e-10 60\n",
      "1e-10 70\n",
      "1e-10 80\n",
      "1e-10 90\n",
      "1e-10 100\n",
      "The logistic loss and accuracy for lambda = 1e-10 are : 0.5126, 1.000000 \n",
      "1e-09 10\n",
      "1e-09 20\n",
      "1e-09 30\n",
      "1e-09 40\n",
      "1e-09 50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-5d082d11d82f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*************KLR for dataset 0*************\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred_klr_tr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas_klr_tr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_klr_tr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_klr_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_tr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*************KLR for dataset 1*************\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred_klr_tr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas_klr_tr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_klr_tr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_klr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_tr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-265-7a28a41b8a7a>\u001b[0m in \u001b[0;36mKLR\u001b[0;34m(K, y, lambd, maxIter, tresh)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mold_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0malpha_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolveWKRR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mm_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0malpha_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-a707a87497b7>\u001b[0m in \u001b[0;36msolveWKRR\u001b[0;34m(K, W, z, y, lambd)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mW_sq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0minv_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_sq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW_sq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_sq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW_sq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0minv_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,0)]\n",
    "print(\"*************KLR for dataset 0*************\\n\")\n",
    "pred_klr_tr0, alphas_klr_tr0, loss_klr_tr0, accuracies_klr_0 = KLR(K_tr0, Ytr0[:,1], lambdas, tresh=1e-5)\n",
    "print(\"*************KLR for dataset 1*************\\n\")\n",
    "pred_klr_tr1, alphas_klr_tr1, loss_klr_tr1, accuracies_klr_1 = KLR(K_tr1, Ytr1[:,1], lambdas, tresh=1e-5)\n",
    "print(\"*************KLR for dataset 2*************\\n\")\n",
    "pred_klr_tr2, alphas_klr_tr2, loss_klr_tr2, accuracies_klr_2 = KLR(K_tr2, Ytr2[:,1], lambdas, tresh=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-stephen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
