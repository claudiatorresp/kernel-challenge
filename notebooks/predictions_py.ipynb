{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metric-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from classifiers import *\n",
    "from metrics import *\n",
    "from kernels import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split # lui il va partir mais pour l'instant c'est pratique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valuable-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_mat100 = np.genfromtxt(\"data/Xtr0_mat100.csv\", delimiter='')\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1_mat100 = np.genfromtxt(\"data/Xtr1_mat100.csv\", delimiter='')\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2_mat100 = np.genfromtxt(\"data/Xtr2_mat100.csv\", delimiter='')\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stuffed-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0, Xval0, ytr0, yval0 = train_test_split(Xtr0_mat100, Ytr0, test_size=0.8, random_state=42)\n",
    "Xtr1, Xval1, ytr1, yval1 = train_test_split(Xtr1_mat100, Ytr1, test_size=0.8, random_state=42)\n",
    "Xtr2, Xval2, ytr2, yval2 = train_test_split(Xtr2_mat100, Ytr2, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-machine",
   "metadata": {},
   "source": [
    "## Create the kernel matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formal-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0_ln, K_val0_ln = linear_kernel(Xtr0, Xval0)\n",
    "K_tr1_ln, K_val1_ln = linear_kernel(Xtr1, Xval1)\n",
    "K_tr2_ln, K_val2_ln = linear_kernel(Xtr2, Xval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pediatric-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0, K_val0 = gaussian_kernel(Xtr0, Xval0)\n",
    "K_tr1, K_val1 = gaussian_kernel(Xtr1, Xval1)\n",
    "K_tr2, K_val2 = gaussian_kernel(Xtr2, Xval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "registered-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0_poly, K_val0_poly = polynomial_kernel(Xtr0, Xval0, d=3, c=1)\n",
    "K_tr1_poly, K_val1_poly = polynomial_kernel(Xtr1, Xval1, d=3, c=1)\n",
    "K_tr2_poly, K_val2_poly = polynomial_kernel(Xtr2, Xval2, d=3, c=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-export",
   "metadata": {},
   "source": [
    "## We test only one kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accomplished-scout",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* SVM for dataset 0 *************\n",
      "\n",
      "---------------  lambda = 0.0005  ---------------\n",
      "Training: loss = 0.032328, accuracy = 0.995000\n",
      "Validation: loss = 0.902603, accuracy = 0.570625\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0005  ---------------\n",
      "Training: loss = 0.046552, accuracy = 0.997500\n",
      "Validation: loss = 0.950284, accuracy = 0.543125\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0005  ---------------\n",
      "Training: loss = 0.026754, accuracy = 0.997500\n",
      "Validation: loss = 0.773108, accuracy = 0.687500\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0.0005]\n",
    "print(\"************* SVM for dataset 0 *************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = SVM(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = SVM(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-mathematics",
   "metadata": {},
   "source": [
    "## example predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "radio-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte0 = np.genfromtxt(\"data/Xte0_mat100.csv\", delimiter='')\n",
    "Xte1 = np.genfromtxt(\"data/Xte1_mat100.csv\", delimiter='')\n",
    "Xte2 = np.genfromtxt(\"data/Xte2_mat100.csv\", delimiter='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "understood-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_te0 = gaussian_kernel(Xtr0, Xte0, mode=\"test\")\n",
    "K_te1 = gaussian_kernel(Xtr1, Xte1, mode=\"test\")\n",
    "K_te2 = gaussian_kernel(Xtr2, Xte2, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "buried-diana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving predictions\n",
      "saved predictions\n"
     ]
    }
   ],
   "source": [
    "test_kernels = [K_te0, K_te1, K_te2]\n",
    "test_alphas = [alphas_tr0[0], alphas_tr1[0], alphas_tr2[0]]\n",
    "write_predictions_csv(test_kernels, test_alphas, path =\"data/Ytest_SVM1e-4.csv\", mode=\"KRR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-paraguay",
   "metadata": {},
   "source": [
    "# Testing the accuracy on sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "def features_into_array(path):\n",
    "    with open(path, 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        X = list()\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                # row variable is a list that represents a row in csv\n",
    "                X.append(np.array(row[1]))\n",
    "                \n",
    "    X = np.array(X) ## dtype might be changed in something more convenient. For now, dtype = \"<U1\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_seq = features_into_array(\"data/Xtr0.csv\")\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1_seq = features_into_array(\"data/Xtr1.csv\")\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2_seq = features_into_array(\"data/Xtr2.csv\")\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0, Xval0, ytr0, yval0 = train_test_split(Xtr0_seq, Ytr0, test_size=0.5, random_state=42)\n",
    "Xtr1, Xval1, ytr1, yval1 = train_test_split(Xtr1_seq, Ytr1, test_size=0.5, random_state=42)\n",
    "Xtr2, Xval2, ytr2, yval2 = train_test_split(Xtr2_seq, Ytr2, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-textbook",
   "metadata": {},
   "source": [
    "## Predictions on the testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte0_seq = features_into_array(\"data/Xte0.csv\")\n",
    "Xte1_seq = features_into_array(\"data/Xte1.csv\")\n",
    "Xte2_seq = features_into_array(\"data/Xte2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-domestic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
