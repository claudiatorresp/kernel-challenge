{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from itertools import product\n",
    "import functools \n",
    "import operator \n",
    "import regex as re\n",
    "import time\n",
    "\n",
    "from classifiers import *\n",
    "from metrics import *\n",
    "from kernels import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split # lui il va partir mais pour l'instant c'est pratique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "def features_into_array(path):\n",
    "    with open(path, 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        X = list()\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                # row variable is a list that represents a row in csv\n",
    "                X.append(np.array(row[1]))\n",
    "                \n",
    "    X = np.array(X) ## dtype might be changed in something more convenient. For now, dtype = \"<U1\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0 = features_into_array(\"data/Xtr0.csv\")\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1 = features_into_array(\"data/Xtr1.csv\")\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2 = features_into_array(\"data/Xtr2.csv\")\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCCTGTGCACATCTGCACCCCTGTTGTGGCCACAAAATGATCCGGCACCACCCAGTGGGAGACGACAGAGGTGGCAATGGGGTGTCGGCTCTGACGCCTCC'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum kernel\n",
    "\n",
    "For a fixed value k (that needs to be tuned), the k-spectrum kernel is defined as : \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "K(x,x^{\\prime}) := \\sum_{u \\in \\mathcal{A}^k} \\phi_{u}(x) \\phi_{u}(x^{\\prime})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_substrings(k):\n",
    "    \"\"\"\n",
    "    With a k spectrum kernel, let us find all the possible combinations of chars of size k in the sequence x\n",
    "    This way, we could index them in the sequence x\n",
    "    \"\"\"\n",
    "    char_list = list(['A', 'C','G','T'])\n",
    "    alphabet_tuples = list(product(char_list,repeat=k))\n",
    "    alphabet = dict()\n",
    "    idx=0\n",
    "    for i in alphabet_tuples:\n",
    "        alphabet[functools.reduce(operator.add, (i))] = idx\n",
    "        idx += 1\n",
    "        #alphabet.append(functools.reduce(operator.add, (i)))\n",
    "    return alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict6 = all_possible_substrings(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_indexing(X, k, alphabet=None):\n",
    "    \"\"\"\n",
    "    Outputs a sparse matrix of shape Transforms an input array into a sparse matrix encoding the number of occurences of each letter of\n",
    "    the alphabet composed of substrings of size k\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    n = X.shape[0]\n",
    "    if alphabet is None:\n",
    "        alphabet = all_possible_substrings(k)\n",
    "    D = np.zeros((n,len(alphabet)))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        idx=0\n",
    "        while idx + k < len(X[i]):\n",
    "            D[i, alphabet[X[i][idx:idx+k]]] += 1\n",
    "            idx += 1\n",
    "    \"\"\"\n",
    "    for x in X:\n",
    "        d = dict((letter, len(re.findall(letter, x, overlapped=True))) \n",
    "                             for letter in alphabet)\n",
    "        data = np.array(list(d.items()))\n",
    "        D[i] = data[:,1]\n",
    "        i+=1\n",
    "    \"\"\"\n",
    "    D = csr_matrix(D, dtype = int)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 1.7300939559936523 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "start_time = time.time()\n",
    "alphabet_6 = all_possible_substrings(k)\n",
    "mm = pre_indexing(Xtr0, 6, alphabet=alphabet_6)\n",
    "print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_kernel(X_train, X_val, X_test, k, alphabet=None):\n",
    "    # Kill two birds with one stone and compute K_train, K_val and K_test all at once.\n",
    "    \"\"\"\n",
    "    Computes the spectrum kernels for X_train (n_train x n_train), X_validation and X_test\n",
    "    (on the RKHS generated by X_train's samples) which is of shape n_validation x n_train (resp n_test x n_train)\n",
    "    \"\"\"\n",
    "    if alphabet is None:\n",
    "        #D_train = pre_indexing(X_train,k).toarray()\n",
    "        #D_val = pre_indexing(X_val,k).toarray()\n",
    "        alphabet = all_possible_substrings(k)\n",
    "   \n",
    "    D_train = pre_indexing(X_train,k,alphabet)\n",
    "    D_val = pre_indexing(X_val,k,alphabet)\n",
    "    D_test = pre_indexing(X_test,k,alphabet)\n",
    "        \n",
    "        \n",
    "    #K_val = np.inner(D_val, D_train)\n",
    "    #K_val = K_val.astype('float')\n",
    "    \n",
    "    K_train = D_train.dot(D_train.transpose())\n",
    "    K_train = K_train.toarray().astype('float')\n",
    "    \n",
    "    K_val = D_val.dot(D_train.transpose())\n",
    "    K_val = K_val.toarray().astype('float')\n",
    "    \n",
    "    K_test = D_test.dot(D_train.transpose())\n",
    "    K_test = K_test.toarray().astype('float')\n",
    "    \n",
    "        \n",
    "    return(K_train, K_val, K_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the spectrum-kernels for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0_, Xval0_, ytr0, yval0 = train_test_split(Xtr0, Ytr0, test_size=0.5, random_state=42)\n",
    "Xtr1_, Xval1_, ytr1, yval1 = train_test_split(Xtr1, Ytr1, test_size=0.5, random_state=42)\n",
    "Xtr2_, Xval2_, ytr2, yval2 = train_test_split(Xtr2, Ytr2, test_size=0.5, random_state=42)\n",
    "\n",
    "Xte0 = features_into_array(\"data/Xte0.csv\")\n",
    "Xte1 = features_into_array(\"data/Xte1.csv\")\n",
    "Xte2 = features_into_array(\"data/Xte2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 0.19686412811279297 seconds ---\n",
      "--- Computed kernel in 9.518135070800781 seconds ---\n",
      "--- Computed kernel in 9.735282182693481 seconds ---\n",
      "--- Computed kernel in 10.768494129180908 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k = 8\n",
    "start_time = time.time()\n",
    "alphabet_8 = all_possible_substrings(k)\n",
    "print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "\n",
    "K_tr0, K_val0, K_te0 = spectrum_kernel(Xtr0_, Xval0_, Xte0, k, alphabet=alphabet_8,)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "K_tr1, K_val1, K_te1 = spectrum_kernel(Xtr1_, Xval1_, Xte1, k, alphabet=alphabet_8)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "K_tr2, K_val2, K_te2 = spectrum_kernel(Xtr2_, Xval2_, Xte2, k, alphabet=alphabet_8)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-Validation\n",
    "(runs to make sure everything is ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* KRR for dataset 0*************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 500.9277, accuracy = 1.000000\n",
      "Validation: loss = 305.9762, accuracy = 0.553000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 500.9277, accuracy = 1.000000\n",
      "Validation: loss = 305.9762, accuracy = 0.553000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 500.9277, accuracy = 1.000000\n",
      "Validation: loss = 305.9762, accuracy = 0.553000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 500.9276, accuracy = 1.000000\n",
      "Validation: loss = 305.9762, accuracy = 0.553000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 500.9271, accuracy = 1.000000\n",
      "Validation: loss = 305.9762, accuracy = 0.553000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 500.9222, accuracy = 1.000000\n",
      "Validation: loss = 305.9760, accuracy = 0.553000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 500.8728, accuracy = 1.000000\n",
      "Validation: loss = 305.9738, accuracy = 0.553000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 500.3800, accuracy = 1.000000\n",
      "Validation: loss = 305.9517, accuracy = 0.553000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 495.5487, accuracy = 1.000000\n",
      "Validation: loss = 305.7422, accuracy = 0.556000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 455.1723, accuracy = 1.000000\n",
      "Validation: loss = 304.4950, accuracy = 0.555000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 325.3965, accuracy = 0.991000\n",
      "Validation: loss = 314.7797, accuracy = 0.517000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 363.2414, accuracy = 0.535000\n",
      "Validation: loss = 409.2623, accuracy = 0.503000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 447.7300, accuracy = 0.535000\n",
      "Validation: loss = 482.6712, accuracy = 0.503000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 503.1629, accuracy = 1.000000\n",
      "Validation: loss = 293.7349, accuracy = 0.559000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 503.1629, accuracy = 1.000000\n",
      "Validation: loss = 293.7349, accuracy = 0.559000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 503.1629, accuracy = 1.000000\n",
      "Validation: loss = 293.7349, accuracy = 0.559000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 503.1628, accuracy = 1.000000\n",
      "Validation: loss = 293.7349, accuracy = 0.559000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 503.1623, accuracy = 1.000000\n",
      "Validation: loss = 293.7349, accuracy = 0.559000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 503.1575, accuracy = 1.000000\n",
      "Validation: loss = 293.7348, accuracy = 0.559000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 503.1092, accuracy = 1.000000\n",
      "Validation: loss = 293.7338, accuracy = 0.559000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 502.6265, accuracy = 1.000000\n",
      "Validation: loss = 293.7239, accuracy = 0.558000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 497.8844, accuracy = 1.000000\n",
      "Validation: loss = 293.6275, accuracy = 0.559000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 457.6720, accuracy = 1.000000\n",
      "Validation: loss = 293.0213, accuracy = 0.552000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 326.1965, accuracy = 1.000000\n",
      "Validation: loss = 304.7785, accuracy = 0.509000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 377.8364, accuracy = 0.509000\n",
      "Validation: loss = 412.9190, accuracy = 0.490000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 472.9119, accuracy = 0.509000\n",
      "Validation: loss = 495.1684, accuracy = 0.490000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 539.3335, accuracy = 1.000000\n",
      "Validation: loss = 329.9253, accuracy = 0.665000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 503.0389, accuracy = 1.000000\n",
      "Validation: loss = 321.4201, accuracy = 0.676000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 503.0389, accuracy = 1.000000\n",
      "Validation: loss = 321.4201, accuracy = 0.676000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 503.0389, accuracy = 1.000000\n",
      "Validation: loss = 321.4201, accuracy = 0.676000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 503.0384, accuracy = 1.000000\n",
      "Validation: loss = 321.4200, accuracy = 0.676000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 503.0341, accuracy = 1.000000\n",
      "Validation: loss = 321.4197, accuracy = 0.676000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 502.9909, accuracy = 1.000000\n",
      "Validation: loss = 321.4159, accuracy = 0.676000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 502.5602, accuracy = 1.000000\n",
      "Validation: loss = 321.3786, accuracy = 0.676000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 498.3336, accuracy = 1.000000\n",
      "Validation: loss = 321.0167, accuracy = 0.677000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 462.6347, accuracy = 1.000000\n",
      "Validation: loss = 318.2023, accuracy = 0.669000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 339.9695, accuracy = 0.998000\n",
      "Validation: loss = 316.3695, accuracy = 0.578000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 378.7457, accuracy = 0.499000\n",
      "Validation: loss = 399.6045, accuracy = 0.504000\n",
      "***********lambda = 10***********\n",
      "Training: loss = 480.3276, accuracy = 0.499000\n",
      "Validation: loss = 480.1971, accuracy = 0.504000\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "\n",
    "print(\"************* KRR for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KRR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* KRR for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = KRR(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* KRR for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = KRR(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************KLR for dataset 0*************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3147, accuracy = 1.000000\n",
      "Validation: loss = 0.6500, accuracy = 0.616000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3267, accuracy = 1.000000\n",
      "Validation: loss = 0.6498, accuracy = 0.619000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.4057, accuracy = 1.000000\n",
      "Validation: loss = 0.6512, accuracy = 0.625000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.5857, accuracy = 0.980000\n",
      "Validation: loss = 0.6649, accuracy = 0.631000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6745, accuracy = 0.967000\n",
      "Validation: loss = 0.6852, accuracy = 0.605000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3147, accuracy = 1.000000\n",
      "Validation: loss = 0.6621, accuracy = 0.600000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3270, accuracy = 1.000000\n",
      "Validation: loss = 0.6626, accuracy = 0.603000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.4095, accuracy = 1.000000\n",
      "Validation: loss = 0.6673, accuracy = 0.608000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.5985, accuracy = 0.999000\n",
      "Validation: loss = 0.6825, accuracy = 0.618000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6805, accuracy = 0.995000\n",
      "Validation: loss = 0.6915, accuracy = 0.618000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3145, accuracy = 1.000000\n",
      "Validation: loss = 0.5982, accuracy = 0.705000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3253, accuracy = 1.000000\n",
      "Validation: loss = 0.5989, accuracy = 0.708000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.3978, accuracy = 0.999000\n",
      "Validation: loss = 0.6073, accuracy = 0.713000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.5743, accuracy = 0.994000\n",
      "Validation: loss = 0.6422, accuracy = 0.713000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6718, accuracy = 0.984000\n",
      "Validation: loss = 0.6800, accuracy = 0.711000\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-4,1)]\n",
    "\n",
    "print(\"*************KLR for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KLR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas, tresh=1e-8)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* KLR for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = KLR(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas, tresh=1e-8)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* KLR for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = KLR(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas, tresh= 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.982613, accuracy = 0.955000\n",
      "Validation: loss = 0.991697, accuracy = 0.598000\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.837311, accuracy = 0.962000\n",
      "Validation: loss = 0.925864, accuracy = 0.601000\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.117413, accuracy = 0.988000\n",
      "Validation: loss = 0.854595, accuracy = 0.635000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.879713, accuracy = 0.611000\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.879708, accuracy = 0.611000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.879703, accuracy = 0.611000\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.879709, accuracy = 0.611000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.989443, accuracy = 0.994000\n",
      "Validation: loss = 0.998564, accuracy = 0.617000\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.894442, accuracy = 0.994000\n",
      "Validation: loss = 0.985645, accuracy = 0.618000\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.114012, accuracy = 0.999000\n",
      "Validation: loss = 0.914992, accuracy = 0.618000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.915494, accuracy = 0.604000\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.915497, accuracy = 0.604000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.915496, accuracy = 0.604000\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.915497, accuracy = 0.604000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.980124, accuracy = 0.984000\n",
      "Validation: loss = 0.986720, accuracy = 0.710000\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.813340, accuracy = 0.985000\n",
      "Validation: loss = 0.880305, accuracy = 0.711000\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.096879, accuracy = 0.997000\n",
      "Validation: loss = 0.745153, accuracy = 0.710000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.753381, accuracy = 0.702000\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.753376, accuracy = 0.702000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.753381, accuracy = 0.702000\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.753377, accuracy = 0.702000\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-4, 3)]\n",
    "print(\"************* SVM for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = SVM(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = SVM(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Sklearn SVM on dataset 0 ***************\n",
      "1.0\n",
      "0.61\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.879708, accuracy = 0.611000\n",
      "\n",
      "\n",
      "\n",
      "***************Sklearn SVM on dataset 1 ***************\n",
      "1.0\n",
      "0.603\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.915497, accuracy = 0.604000\n",
      "\n",
      "\n",
      "\n",
      "***************Sklearn SVM on dataset 2 ***************\n",
      "1.0\n",
      "0.703\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.753376, accuracy = 0.702000\n"
     ]
    }
   ],
   "source": [
    "# sanity check to see that our SVM does a good job\n",
    "# C = 1/(2*n*lambda) \n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='precomputed', C =1.)\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 0 \" + \"*\"*15)\n",
    "clf.fit(K_tr0, ytr0[:,1])\n",
    "print(clf.score(K_tr0, ytr0[:,1]))\n",
    "print(clf.score(K_val0, yval0[:,1]))\n",
    "lambd_C = [1]\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambd_C)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 1 \" + \"*\"*15)\n",
    "clf.fit(K_tr1, ytr1[:,1])\n",
    "print(clf.score(K_tr1, ytr1[:,1]))\n",
    "print(clf.score(K_val1, yval1[:,1]))\n",
    "lambd_C = [1]\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = SVM(K_tr1, ytr1[:,1], K_val1, yval1[:,1], lambd_C)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 2 \" + \"*\"*15)\n",
    "clf.fit(K_tr2, ytr2[:,1])\n",
    "print(clf.score(K_tr2, ytr2[:,1]))\n",
    "print(clf.score(K_val2, yval2[:,1]))\n",
    "lambd_C = [1]\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = SVM(K_tr2, ytr2[:,1], K_val2, yval2[:,1], lambd_C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay cool almost there let's do gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************treating k=3***************\n",
      "--- Found alphabet in 0.00162506103515625 seconds ---\n",
      "--- Computed all the kernels in 8.833793878555298 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=4***************\n",
      "--- Found alphabet in 0.0005450248718261719 seconds ---\n",
      "--- Computed all the kernels in 8.055458068847656 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=5***************\n",
      "--- Found alphabet in 0.001964092254638672 seconds ---\n",
      "--- Computed all the kernels in 8.84161376953125 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=6***************\n",
      "--- Found alphabet in 0.01622772216796875 seconds ---\n",
      "--- Computed all the kernels in 9.374190092086792 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=7***************\n",
      "--- Found alphabet in 0.05209493637084961 seconds ---\n",
      "--- Computed all the kernels in 10.316075086593628 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=8***************\n",
      "--- Found alphabet in 0.23636889457702637 seconds ---\n",
      "--- Computed all the kernels in 27.527786016464233 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=9***************\n",
      "--- Found alphabet in 0.9420952796936035 seconds ---\n",
      "--- Computed all the kernels in 86.68662405014038 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=10***************\n",
      "--- Found alphabet in 4.612468004226685 seconds ---\n",
      "--- Computed all the kernels in 390.088830947876 seconds ---\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Kernels_tr_0 = []\n",
    "Kernels_val_0 = []\n",
    "Kernels_te_0 = []\n",
    "\n",
    "Kernels_tr_1 = []\n",
    "Kernels_val_1 = []\n",
    "Kernels_te_1 = []\n",
    "\n",
    "Kernels_tr_2 = []\n",
    "Kernels_val_2 = []\n",
    "Kernels_te_2 = []\n",
    "\n",
    "\n",
    "for k in range(3,11):\n",
    "    \n",
    "    print(\"*\"*15 + \"treating k=\" + str(k) + 15*\"*\")\n",
    "    start_time = time.time()\n",
    "    alphabet_k = all_possible_substrings(k)\n",
    "    print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    K_tr0, K_val0, K_te0 = spectrum_kernel(Xtr0_, Xval0_, Xte0, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_0 += [K_tr0]\n",
    "    Kernels_val_0 += [K_val0]\n",
    "    Kernels_te_0 += [K_te0]\n",
    "    \n",
    "    K_tr1, K_val1, K_te1 = spectrum_kernel(Xtr1_, Xval1_, Xte1, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_1 += [K_tr1]\n",
    "    Kernels_val_1 += [K_val1]\n",
    "    Kernels_te_1 += [K_te1]\n",
    "    \n",
    "    K_tr2, K_val2, K_te2 = spectrum_kernel(Xtr2_, Xval2_, Xte2, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_2 += [K_tr2]\n",
    "    Kernels_val_2 += [K_val2]\n",
    "    Kernels_te_2 += [K_te2]\n",
    "    \n",
    "    print(\"--- Computed all the kernels in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************treating k = 5***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.004, kernel='precomputed')\n",
      "training score for k = 5  0.778\n",
      "validation score for k = 5  0.598\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.007, kernel='precomputed')\n",
      "training score for k = 5  0.832\n",
      "validation score for k = 5  0.623\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.007, kernel='precomputed')\n",
      "training score for k = 5  0.859\n",
      "validation score for k = 5  0.7\n",
      "\n",
      "\n",
      "***************treating k = 6***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.009000000000000001, kernel='precomputed')\n",
      "training score for k = 6  0.936\n",
      "validation score for k = 6  0.602\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.004, kernel='precomputed')\n",
      "training score for k = 6  0.892\n",
      "validation score for k = 6  0.611\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.007, kernel='precomputed')\n",
      "training score for k = 6  0.93\n",
      "validation score for k = 6  0.722\n",
      "\n",
      "\n",
      "***************treating k = 7***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.01, kernel='precomputed')\n",
      "training score for k = 7  0.983\n",
      "validation score for k = 7  0.64\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.007, kernel='precomputed')\n",
      "training score for k = 7  0.988\n",
      "validation score for k = 7  0.614\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.007, kernel='precomputed')\n",
      "training score for k = 7  0.973\n",
      "validation score for k = 7  0.721\n",
      "\n",
      "\n",
      "***************treating k = 8***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.008, kernel='precomputed')\n",
      "training score for k = 8  0.984\n",
      "validation score for k = 8  0.634\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.009000000000000001, kernel='precomputed')\n",
      "training score for k = 8  0.999\n",
      "validation score for k = 8  0.608\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 8  0.998\n",
      "validation score for k = 8  0.708\n",
      "\n",
      "\n",
      "***************treating k = 9***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 9  0.998\n",
      "validation score for k = 9  0.64\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.01, kernel='precomputed')\n",
      "training score for k = 9  0.999\n",
      "validation score for k = 9  0.582\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.05, kernel='precomputed')\n",
      "training score for k = 9  1.0\n",
      "validation score for k = 9  0.704\n",
      "\n",
      "\n",
      "***************treating k = 10***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.03, kernel='precomputed')\n",
      "training score for k = 10  1.0\n",
      "validation score for k = 10  0.608\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 10  1.0\n",
      "validation score for k = 10  0.569\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 10  0.998\n",
      "validation score for k = 10  0.689\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "values_C = [j*10**i for i in range(-5,3) for j in range(1,10)]\n",
    "parameters = {'C': values_C}\n",
    "svm__ = svm.SVC(kernel='precomputed')\n",
    "gs_k = GridSearchCV(svm__, param_grid=parameters, refit=True, verbose=0)\n",
    "\n",
    "for k in range(2,8):\n",
    "    \n",
    "        \n",
    "    print(\"*\"*15 + \"treating k = \" + str(k+3) + 15*\"*\")\n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 0 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_0[k], ytr0[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_0[k], ytr0[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_0[k], yval0[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 1 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_1[k], ytr1[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_1[k], ytr1[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_1[k], yval1[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 2 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_2[k], ytr2[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_2[k], ytr2[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_2[k], yval2[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuck it lets do for k = 11 and 12 too\n",
    "for k in range(11,13):\n",
    "    print(\"*\"*15 + \"treating k=\" + str(k) + 15*\"*\")\n",
    "    start_time = time.time()\n",
    "    alphabet_k = all_possible_substrings(k)\n",
    "    print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    K_tr0, K_val0, K_te0 = spectrum_kernel(Xtr0_, Xval0_, Xte0, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_0 += [K_tr0]\n",
    "    Kernels_val_0 += [K_val0]\n",
    "    Kernels_te_0 += [K_te0]\n",
    "    \n",
    "    K_tr1, K_val1, K_te1 = spectrum_kernel(Xtr1_, Xval1_, Xte1, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_1 += [K_tr1]\n",
    "    Kernels_val_1 += [K_val1]\n",
    "    Kernels_te_1 += [K_te1]\n",
    "    \n",
    "    K_tr2, K_val2, K_te2 = spectrum_kernel(Xtr2_, Xval2_, Xte2, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_2 += [K_tr2]\n",
    "    Kernels_val_2 += [K_val2]\n",
    "    Kernels_te_2 += [K_te2]\n",
    "    \n",
    "    print(\"--- Computed all the kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forget it im scared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernels = [K_te0, K_te1, K_te2]\n",
    "#test_alphas = [alphas_tr0[-4], alphas_tr1[-4], alphas_tr2[-3]] # il faut choisir l'alpha associé à un bon lambda!\n",
    "test_alphas = [alphas_tr0[0], alphas_tr1[0], alphas_tr2[0]]\n",
    "write_predictions_csv(test_kernels, test_alphas, path =\"data/Ytest_sequences.csv\", mode=\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_te0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_tr0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_te0[0,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
