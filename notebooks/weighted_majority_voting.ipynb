{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "personal-advertiser",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "competent-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from itertools import product\n",
    "import functools \n",
    "import operator \n",
    "import regex as re\n",
    "import time\n",
    "\n",
    "from classifiers import *\n",
    "from metrics import *\n",
    "from kernels import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split # lui il va partir mais pour l'instant c'est pratique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "opening-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-banks",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "czech-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtr0 = features_into_array(\"data/Xtr0.csv\")\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "#Xtr1 = features_into_array(\"data/Xtr1.csv\")\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "#Xtr2 = features_into_array(\"data/Xtr2.csv\")\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "innocent-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx_0 = np.load(\"train_test_split/train_idx_0.npy\").astype(int)\n",
    "train_idx_1 = np.load(\"train_test_split/train_idx_1.npy\").astype(int)\n",
    "train_idx_2 = np.load(\"train_test_split/train_idx_2.npy\").astype(int)\n",
    "\n",
    "val_idx_0 = np.load(\"train_test_split/val_idx_0.npy\").astype(int)\n",
    "val_idx_1 = np.load(\"train_test_split/val_idx_1.npy\").astype(int)\n",
    "val_idx_2 = np.load(\"train_test_split/val_idx_2.npy\").astype(int)\n",
    "\n",
    "ytr0 = Ytr0[train_idx_0]\n",
    "ytr1 = Ytr1[train_idx_1 - 2000]\n",
    "ytr2 = Ytr2[train_idx_2 - 4000]\n",
    "\n",
    "yval0 = Ytr0[val_idx_0]\n",
    "yval1 = Ytr1[val_idx_1 - 2000]\n",
    "yval2 = Ytr2[val_idx_2 - 4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-acquisition",
   "metadata": {},
   "source": [
    "## Load the  kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sixth-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-computed spectrum kernels for k = 5 to k = 10\n",
    "\n",
    "# Dataset zero\n",
    "K_tr0_spectrum = np.load(\"spectrum/K_train0.npy\")\n",
    "K_val0_spectrum = np.load(\"spectrum/K_val0.npy\")\n",
    "K_te0_spectrum = np.load(\"spectrum/K_te0.npy\")\n",
    "\n",
    "# Dataset one\n",
    "K_tr1_spectrum = np.load(\"spectrum/K_train1.npy\")\n",
    "K_val1_spectrum = np.load(\"spectrum/K_val1.npy\")\n",
    "K_te1_spectrum = np.load(\"spectrum/K_te1.npy\")\n",
    "\n",
    "# Dataset two\n",
    "K_tr2_spectrum = np.load(\"spectrum/K_train2.npy\")\n",
    "K_val2_spectrum = np.load(\"spectrum/K_val2.npy\")\n",
    "K_te2_spectrum = np.load(\"spectrum/K_te2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "olive-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-computed mismatch kernels for k = 5 to k = 10 and m = 1\n",
    "\n",
    "# Dataset zero\n",
    "K_tr0_mismatch = np.load(\"mismatch/K_train0.npy\")\n",
    "K_val0_mismatch = np.load(\"mismatch/K_val0.npy\")\n",
    "K_te0_mismatch = np.load(\"mismatch/K_te0.npy\")\n",
    "\n",
    "# Dataset one\n",
    "K_tr1_mismatch = np.load(\"mismatch/K_train1.npy\")\n",
    "K_val1_mismatch = np.load(\"mismatch/K_val1.npy\")\n",
    "K_te1_mismatch = np.load(\"mismatch/K_te1.npy\")\n",
    "\n",
    "# Dataset two\n",
    "K_tr2_mismatch = np.load(\"mismatch/K_train2.npy\")\n",
    "K_val2_mismatch = np.load(\"mismatch/K_val2.npy\")\n",
    "K_te2_mismatch = np.load(\"mismatch/K_te2.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-wyoming",
   "metadata": {},
   "source": [
    "# Get the alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-stuart",
   "metadata": {},
   "source": [
    "### First we get the best C found in a gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forced-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_mismatch_0 = [0.0004, 0.0002, 0.0001, 0.0004, 0.0003, 0.0006]\n",
    "C_mismatch_1 = [0.0003, 0.0004, 0.0002, 0.0005, 0.0004, 0.0003]\n",
    "C_mismatch_2 = [0.0002, 0.0005, 0.0005, 0.0004, 0.0004, 0.001]\n",
    "\n",
    "C_spectrum_0 = [0.002, 0.003, 0.009, 0.01, 0.02, 0.02]\n",
    "C_spectrum_1 = [0.005, 0.004, 0.007, 0.009, 0.01, 0.02]\n",
    "C_spectrum_2 = [0.006, 0.008, 0.01, 0.08, 0.02, 0.02]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "boxed-reality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Treating mismatch kernels for k = 5 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0004  ---------------\n",
      "Training: loss = 0.632025, accuracy = 0.718750\n",
      "Validation: loss = 0.791007, accuracy = 0.617500\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0003  ---------------\n",
      "Training: loss = 0.655350, accuracy = 0.730000\n",
      "Validation: loss = 0.818788, accuracy = 0.610000\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0002  ---------------\n",
      "Training: loss = 0.553185, accuracy = 0.779375\n",
      "Validation: loss = 0.655252, accuracy = 0.727500\n",
      "\n",
      "\n",
      "***************Treating mismatch kernels for k = 6 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0002  ---------------\n",
      "Training: loss = 0.605278, accuracy = 0.761875\n",
      "Validation: loss = 0.777157, accuracy = 0.672500\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0004  ---------------\n",
      "Training: loss = 0.467750, accuracy = 0.833125\n",
      "Validation: loss = 0.768899, accuracy = 0.655000\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0005  ---------------\n",
      "Training: loss = 0.323933, accuracy = 0.891875\n",
      "Validation: loss = 0.624706, accuracy = 0.722500\n",
      "\n",
      "\n",
      "***************Treating mismatch kernels for k = 7 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.645104, accuracy = 0.778125\n",
      "Validation: loss = 0.777120, accuracy = 0.657500\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0002  ---------------\n",
      "Training: loss = 0.503318, accuracy = 0.865000\n",
      "Validation: loss = 0.798266, accuracy = 0.672500\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0005  ---------------\n",
      "Training: loss = 0.193452, accuracy = 0.954375\n",
      "Validation: loss = 0.616601, accuracy = 0.757500\n",
      "\n",
      "\n",
      "***************Treating mismatch kernels for k = 8 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0004  ---------------\n",
      "Training: loss = 0.198255, accuracy = 0.976875\n",
      "Validation: loss = 0.774917, accuracy = 0.672500\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0005  ---------------\n",
      "Training: loss = 0.123711, accuracy = 0.995000\n",
      "Validation: loss = 0.772329, accuracy = 0.670000\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0004  ---------------\n",
      "Training: loss = 0.144182, accuracy = 0.981250\n",
      "Validation: loss = 0.621558, accuracy = 0.742500\n",
      "\n",
      "\n",
      "***************Treating mismatch kernels for k = 9 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0003  ---------------\n",
      "Training: loss = 0.204469, accuracy = 0.983750\n",
      "Validation: loss = 0.800959, accuracy = 0.675000\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0004  ---------------\n",
      "Training: loss = 0.087248, accuracy = 0.998750\n",
      "Validation: loss = 0.830510, accuracy = 0.662500\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0004  ---------------\n",
      "Training: loss = 0.071560, accuracy = 0.996250\n",
      "Validation: loss = 0.651398, accuracy = 0.765000\n",
      "\n",
      "\n",
      "***************Treating mismatch kernels for k = 10 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0006  ---------------\n",
      "Training: loss = 0.010008, accuracy = 0.995625\n",
      "Validation: loss = 0.855926, accuracy = 0.680000\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0003  ---------------\n",
      "Training: loss = 0.128701, accuracy = 1.000000\n",
      "Validation: loss = 0.878896, accuracy = 0.685000\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.001476, accuracy = 0.999375\n",
      "Validation: loss = 0.697093, accuracy = 0.767500\n",
      "\n",
      "\n",
      "***************Treating spectrum kernels for k = 5 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.002  ---------------\n",
      "Training: loss = 0.686072, accuracy = 0.727500\n",
      "Validation: loss = 0.798497, accuracy = 0.637500\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.005  ---------------\n",
      "Training: loss = 0.559067, accuracy = 0.791875\n",
      "Validation: loss = 0.791559, accuracy = 0.642500\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.006  ---------------\n",
      "Training: loss = 0.440439, accuracy = 0.836875\n",
      "Validation: loss = 0.648491, accuracy = 0.707500\n",
      "\n",
      "\n",
      "***************Treating spectrum kernels for k = 6 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.003  ---------------\n",
      "Training: loss = 0.587996, accuracy = 0.821875\n",
      "Validation: loss = 0.797911, accuracy = 0.647500\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.004  ---------------\n",
      "Training: loss = 0.524851, accuracy = 0.867500\n",
      "Validation: loss = 0.809016, accuracy = 0.645000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.008  ---------------\n",
      "Training: loss = 0.278265, accuracy = 0.927500\n",
      "Validation: loss = 0.629636, accuracy = 0.715000\n",
      "\n",
      "\n",
      "***************Treating spectrum kernels for k = 7 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.009  ---------------\n",
      "Training: loss = 0.227732, accuracy = 0.970625\n",
      "Validation: loss = 0.795442, accuracy = 0.657500\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.007  ---------------\n",
      "Training: loss = 0.316770, accuracy = 0.974375\n",
      "Validation: loss = 0.831072, accuracy = 0.660000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.146837, accuracy = 0.983750\n",
      "Validation: loss = 0.661417, accuracy = 0.705000\n",
      "\n",
      "\n",
      "***************Treating spectrum kernels for k = 8 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.126440, accuracy = 0.988125\n",
      "Validation: loss = 0.842382, accuracy = 0.635000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.009  ---------------\n",
      "Training: loss = 0.168295, accuracy = 0.998125\n",
      "Validation: loss = 0.866640, accuracy = 0.667500\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.08  ---------------\n",
      "Training: loss = 0.000423, accuracy = 1.000000\n",
      "Validation: loss = 0.698896, accuracy = 0.732500\n",
      "\n",
      "\n",
      "***************Treating spectrum kernels for k = 9 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.02  ---------------\n",
      "Training: loss = 0.008491, accuracy = 0.997500\n",
      "Validation: loss = 0.884466, accuracy = 0.610000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.091733, accuracy = 1.000000\n",
      "Validation: loss = 0.910978, accuracy = 0.617500\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.02  ---------------\n",
      "Training: loss = 0.003269, accuracy = 0.998750\n",
      "Validation: loss = 0.730818, accuracy = 0.715000\n",
      "\n",
      "\n",
      "***************Treating spectrum kernels for k = 10 ***************\n",
      "\n",
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.02  ---------------\n",
      "Training: loss = 0.006651, accuracy = 0.998750\n",
      "Validation: loss = 0.898766, accuracy = 0.592500\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.02  ---------------\n",
      "Training: loss = 0.000018, accuracy = 1.000000\n",
      "Validation: loss = 0.935424, accuracy = 0.585000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.02  ---------------\n",
      "Training: loss = 0.002984, accuracy = 0.998750\n",
      "Validation: loss = 0.765092, accuracy = 0.715000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alphas_0 = []\n",
    "alphas_1 = []\n",
    "alphas_2 = []\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    print(\"*\"*15 + f\"Treating mismatch kernels for k = {i+5} \" + \"*\"*15)\n",
    "    print(\"\")\n",
    "    print(\"************* SVM for dataset 0*************\\n\")\n",
    "    \n",
    "    alphas_tr0_mismatch, _,_,_,_ = SVM(K_tr0_mismatch[i], ytr0[:,1], K_val0_mismatch[i],\n",
    "                                       yval0[:,1], [C_mismatch_0[i]])\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"************* SVM for dataset 1 *************\\n\")\n",
    "    \n",
    "    alphas_tr1_mismatch, _,_,_,_ = SVM(K_tr1_mismatch[i], ytr1[:,1], K_val1_mismatch[i],\n",
    "                                       yval1[:,1], [C_mismatch_1[i]])\n",
    "    print(\"\")\n",
    "    print(\"************* SVM for dataset 2 *************\\n\")\n",
    "    alphas_tr2_mismatch, _,_,_,_ = SVM(K_tr2_mismatch[i], ytr2[:,1], K_val2_mismatch[i],\n",
    "                                       yval2[:,1], [C_mismatch_2[i]])\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "    alphas_0 += alphas_tr0_mismatch\n",
    "    alphas_1 += alphas_tr1_mismatch\n",
    "    alphas_2 += alphas_tr2_mismatch\n",
    "    \n",
    "for i in range(6):\n",
    "    print(\"*\"*15 + f\"Treating spectrum kernels for k = {i+5} \" + \"*\"*15)\n",
    "    print(\"\")\n",
    "    print(\"************* SVM for dataset 0*************\\n\")\n",
    "    \n",
    "    alphas_tr0_spectrum, _,_,_,_ = SVM(K_tr0_spectrum[i], ytr0[:,1], K_val0_spectrum[i],\n",
    "                                       yval0[:,1], [C_spectrum_0[i]])\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"************* SVM for dataset 1 *************\\n\")\n",
    "    \n",
    "    alphas_tr1_spectrum, _,_,_,_ = SVM(K_tr1_spectrum[i], ytr1[:,1], K_val1_spectrum[i],\n",
    "                                       yval1[:,1], [C_spectrum_1[i]])\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"************* SVM for dataset 2 *************\\n\")\n",
    "    alphas_tr2_spectrum, _,_,_,_ = SVM(K_tr2_spectrum[i], ytr2[:,1], K_val2_spectrum[i],\n",
    "                                       yval2[:,1], [C_spectrum_2[i]])\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "    alphas_0 += alphas_tr0_spectrum\n",
    "    alphas_1 += alphas_tr1_spectrum\n",
    "    alphas_2 += alphas_tr2_spectrum\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-westminster",
   "metadata": {},
   "source": [
    "# Majority Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-diesel",
   "metadata": {},
   "source": [
    "First we will need to compute for each classifier the accuracy on the training (validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distinguished-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(y):\n",
    "    \"\"\"\n",
    "    takes an array with values in [-1,1] and turns into 0 all the values that are below 0\n",
    "    \"\"\"\n",
    "    y_ = np.zeros(y.shape[0])\n",
    "    y_[y>0] = 1\n",
    "    return(y_)\n",
    "\n",
    "def error(y_true, y_pred):\n",
    "    y_pred_ = to_binary(y_pred)\n",
    "    return(1-np.mean(y_pred_ == y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coordinated-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_weighted_mv(K_train, K_val, alphas, y_train, y_val, K_test=None, gamma= 1/2 ):\n",
    "    \n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    K_train is a list of training kernels\n",
    "    K_val is a list of the respective validation kernels\n",
    "    alphas is a list containing the alpha vector found for each training kernel\n",
    "    \n",
    "    if a K_test is provided, then we also give the predictions for the testing model :o\n",
    "    \n",
    "    OUTPUTS\n",
    "    idk\n",
    "    \"\"\"\n",
    "    prob = 1/(K_train.shape[0])\n",
    "    y_tr_pred = np.zeros(y_train.shape[0])\n",
    "    y_val_pred = np.zeros(y_val.shape[0])\n",
    "    \n",
    "    if K_test is not None:\n",
    "        y_te_pred = np.zeros(1000)\n",
    "    \n",
    "    for i in range(K_train.shape[0]):\n",
    "        \n",
    "        y_tr_i= K_train[i] @ alphas[i]\n",
    "        y_val_i= K_val[i] @ alphas[i]\n",
    "        \n",
    "        #err = error(y_train, y_tr_i)\n",
    "        #if err == 0:\n",
    "        #    err = 10\n",
    "        #else:\n",
    "        #    err = gamma * np.log((1-err)/err)\n",
    "        \n",
    "        #errors += [err]\n",
    "        \n",
    "        y_tr_pred += prob * y_tr_i\n",
    "        y_val_pred += prob * y_val_i\n",
    "        \n",
    "        if K_test is not None:\n",
    "            y_te_pred += prob * (K_test[i] @ alphas[i])\n",
    "    \n",
    "    #print(\"Assigned Weights : \", errors)\n",
    "    print(f\"Training score : {1 - error(y_train, y_tr_pred)}\")\n",
    "    print(f\"Validation score : {1 - error(y_val, y_val_pred)}\")\n",
    "    \n",
    "    if K_test is not None:\n",
    "        return(y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-living",
   "metadata": {},
   "source": [
    "## Our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "norman-mambo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 0.955625\n",
      "Validation score : 0.6675\n",
      "Training score : 0.97125\n",
      "Validation score : 0.675\n",
      "Training score : 0.989375\n",
      "Validation score : 0.7525\n"
     ]
    }
   ],
   "source": [
    "y_te0_pred_mv = no_weighted_mv(K_tr0_mismatch,\n",
    "            K_val0_mismatch,\n",
    "            alphas_0[:6], ytr0[:,1], yval0[:,1],\n",
    "            K_test =K_te0_mismatch)\n",
    "\n",
    "y_te1_pred_mv = no_weighted_mv(K_tr1_mismatch,\n",
    "            K_val1_mismatch,\n",
    "            alphas_1[:6], ytr1[:,1], yval1[:,1],\n",
    "            K_test =K_te1_mismatch)\n",
    "\n",
    "y_te2_pred_mv = no_weighted_mv(K_tr2_mismatch[1:],\n",
    "            K_val2_mismatch[1:],\n",
    "            alphas_2[1:6], ytr2[:,1], yval2[:,1],\n",
    "            K_test =K_te0_mismatch[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-license",
   "metadata": {},
   "source": [
    "Compute the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beneficial-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6983333333333333\n"
     ]
    }
   ],
   "source": [
    "(0.955625 + 0.97125 + 0.989375)/3\n",
    "print((0.6675 +0.675 + 0.7525)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-apollo",
   "metadata": {},
   "source": [
    "# Weighted Majority voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elementary-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mv(K_train, K_val, alphas, y_train, y_val, K_test=None, gamma= 1/2 ):\n",
    "    \n",
    "    \"\"\"\n",
    "    INPUTS\n",
    "    K_train is a list of training kernels\n",
    "    K_val is a list of the respective validation kernels\n",
    "    alphas is a list containing the alpha vector found for each training kernel\n",
    "    \n",
    "    if a K_test is provided, then we also give the predictions for the testing model :o\n",
    "    \n",
    "    OUTPUTS\n",
    "    idk\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    y_tr_pred = np.zeros(y_train.shape[0])\n",
    "    y_val_pred = np.zeros(y_val.shape[0])\n",
    "    \n",
    "    if K_test is not None:\n",
    "        y_te_pred = np.zeros(1000)\n",
    "    \n",
    "    for i in range(K_train.shape[0]):\n",
    "        \n",
    "        y_tr_i= K_train[i] @ alphas[i]\n",
    "        y_val_i= K_val[i] @ alphas[i]\n",
    "        \n",
    "        err = error(y_train, y_tr_i)\n",
    "        if err == 0:\n",
    "            err = 10\n",
    "        else:\n",
    "            err = gamma * np.log((1-err)/err)\n",
    "        \n",
    "        errors += [err]\n",
    "        \n",
    "        y_tr_pred += err * y_tr_i\n",
    "        y_val_pred += err * y_val_i\n",
    "        \n",
    "        if K_test is not None:\n",
    "            y_te_pred += err * (K_test[i] @ alphas[i])\n",
    "    \n",
    "    print(\"Assigned Weights : \", errors)\n",
    "    print(f\"Training score : {1 - error(y_train, y_tr_pred)}\")\n",
    "    print(f\"Validation score : {1 - error(y_val, y_val_pred)}\")\n",
    "    \n",
    "    if K_test is not None:\n",
    "        return(y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-arkansas",
   "metadata": {},
   "source": [
    "## Use only mismatch kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lasting-calendar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned Weights :  [0.4691348192964651, 0.5814933771772852, 0.627386509711696, 1.8717222088886272, 2.051639445477934, 2.7137320804273655]\n",
      "Training score : 0.9875\n",
      "Validation score : 0.68\n",
      "Assigned Weights :  [0.49731128757203097, 0.8039693308892296, 0.9287273642467249, 2.6466524123622457, 3.341680472883148, 10]\n",
      "Training score : 0.998125\n",
      "Validation score : 0.69\n",
      "Assigned Weights :  [1.0550190114895286, 1.5203004320351203, 1.978816758340098, 2.7911211950610486, 3.688566856416988]\n",
      "Training score : 0.9975\n",
      "Validation score : 0.7725\n"
     ]
    }
   ],
   "source": [
    "y_te0_pred_wmv = weighted_mv(K_tr0_mismatch,\n",
    "            K_val0_mismatch,\n",
    "            alphas_0[:6], ytr0[:,1], yval0[:,1],\n",
    "            K_test =K_te0_mismatch)\n",
    "\n",
    "y_te1_pred_wmv = weighted_mv(K_tr1_mismatch,\n",
    "            K_val1_mismatch,\n",
    "            alphas_1[:6], ytr1[:,1], yval1[:,1],\n",
    "            K_test =K_te1_mismatch)\n",
    "\n",
    "y_te2_pred_wmv = weighted_mv(K_tr2_mismatch[1:],\n",
    "            K_val2_mismatch[1:],\n",
    "            alphas_2[1:6], ytr2[:,1], yval2[:,1],\n",
    "            K_test =K_te0_mismatch[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "expensive-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9943750000000001\n",
      "0.7141666666666667\n"
     ]
    }
   ],
   "source": [
    "print((0.9875 + 0.998125 + 0.9975)/3)\n",
    "print((0.68 + 0.69 + 0.7725)/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def write_predictions_csv_good2(y_tests, path, mode=\"SVM\"):\n",
    "    \n",
    "    n = 1000\n",
    "    print(n)\n",
    "    predictions = np.zeros(3*n, dtype=int)\n",
    "    \n",
    "    for i in range(3):\n",
    "        y_pred = y_tests[i]\n",
    "        if mode == 'SVM':\n",
    "            print(\"entered mode SVM\")\n",
    "            y_pred_ = np.ones(n)\n",
    "            y_pred_[y_pred < 0] = 0\n",
    "        else:\n",
    "            y_pred_ = np.zeros(n)\n",
    "            y_pred_[y_pred >= 0.5] = 1\n",
    "   \n",
    "        predictions[n*i:n*(i+1)] = y_pred_\n",
    "    \n",
    "    #predictions = predictions.astype(int)\n",
    "    pred = pd.DataFrame({\"Bound\" : predictions})\n",
    "    print(\"saving predictions\")\n",
    "    pred.to_csv(path, index=True,index_label=\"Id\")\n",
    "    #np.savetxt(\"data/Ytest_KRR.csv\", predictions, header = \"Id, Bound\", delimiter =\",\")\n",
    "    print(\"saved predictions\")\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tests = [y_te0_pred, y_te1_pred, y_te2_pred]\n",
    "aa = write_predictions_csv_good2(y_tests, \"data/Ytest_mj_mismatch12_allbut52.csv\", mode=\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aa[0], aa[1000], aa[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-special",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
