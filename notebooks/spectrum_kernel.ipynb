{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from itertools import product\n",
    "import functools \n",
    "import operator \n",
    "import regex as re\n",
    "import time\n",
    "\n",
    "from classifiers import *\n",
    "from metrics import *\n",
    "from kernels import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split # lui il va partir mais pour l'instant c'est pratique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "def features_into_array(path):\n",
    "    with open(path, 'r') as read_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        header = next(csv_reader)\n",
    "        X = list()\n",
    "        if header != None:\n",
    "            for row in csv_reader:\n",
    "                # row variable is a list that represents a row in csv\n",
    "                X.append(np.array(row[1]))\n",
    "                \n",
    "    X = np.array(X) ## dtype might be changed in something more convenient. For now, dtype = \"<U1\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr0 = features_into_array(\"data/Xtr0.csv\")\n",
    "Ytr0 = np.genfromtxt(\"data/Ytr0.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr1 = features_into_array(\"data/Xtr1.csv\")\n",
    "Ytr1 = np.genfromtxt(\"data/Ytr1.csv\", delimiter=',', skip_header=1)\n",
    "\n",
    "Xtr2 = features_into_array(\"data/Xtr2.csv\")\n",
    "Ytr2 = np.genfromtxt(\"data/Ytr2.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCCTGTGCACATCTGCACCCCTGTTGTGGCCACAAAATGATCCGGCACCACCCAGTGGGAGACGACAGAGGTGGCAATGGGGTGTCGGCTCTGACGCCTCC'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr0[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum kernel\n",
    "\n",
    "For a fixed value k (that needs to be tuned), the k-spectrum kernel is defined as : \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "K(x,x^{\\prime}) := \\sum_{u \\in \\mathcal{A}^k} \\phi_{u}(x) \\phi_{u}(x^{\\prime})\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_substrings(k):\n",
    "    \"\"\"\n",
    "    With a k spectrum kernel, let us find all the possible combinations of chars of size k in the sequence x\n",
    "    This way, we could index them in the sequence x\n",
    "    \"\"\"\n",
    "    char_list = list(['A', 'C','G','T'])\n",
    "    alphabet_tuples = list(product(char_list,repeat=k))\n",
    "    alphabet = dict()\n",
    "    idx=0\n",
    "    for i in alphabet_tuples:\n",
    "        alphabet[functools.reduce(operator.add, (i))] = idx\n",
    "        idx += 1\n",
    "        #alphabet.append(functools.reduce(operator.add, (i)))\n",
    "    return alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict6 = all_possible_substrings(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_indexing(X, k, alphabet=None):\n",
    "    \"\"\"\n",
    "    Outputs a sparse matrix of shape Transforms an input array into a sparse matrix encoding the number of occurences of each letter of\n",
    "    the alphabet composed of substrings of size k\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    n = X.shape[0]\n",
    "    if alphabet is None:\n",
    "        alphabet = all_possible_substrings(k)\n",
    "    D = np.zeros((n,len(alphabet)))\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        idx=0\n",
    "        while idx + k < len(X[i]):\n",
    "            D[i, alphabet[X[i][idx:idx+k]]] += 1\n",
    "            idx += 1\n",
    "    \"\"\"\n",
    "    for x in X:\n",
    "        d = dict((letter, len(re.findall(letter, x, overlapped=True))) \n",
    "                             for letter in alphabet)\n",
    "        data = np.array(list(d.items()))\n",
    "        D[i] = data[:,1]\n",
    "        i+=1\n",
    "    \"\"\"\n",
    "    D = csr_matrix(D, dtype = int)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 1.0961740016937256 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "start_time = time.time()\n",
    "alphabet_6 = all_possible_substrings(k)\n",
    "mm = pre_indexing(Xtr0, 6, alphabet=alphabet_6)\n",
    "print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_kernel(X_train, X_val, X_test, k, alphabet=None):\n",
    "    # Kill two birds with one stone and compute K_train, K_val and K_test all at once.\n",
    "    \"\"\"\n",
    "    Computes the spectrum kernels for X_train (n_train x n_train), X_validation and X_test\n",
    "    (on the RKHS generated by X_train's samples) which is of shape n_validation x n_train (resp n_test x n_train)\n",
    "    \"\"\"\n",
    "    if alphabet is None:\n",
    "        #D_train = pre_indexing(X_train,k).toarray()\n",
    "        #D_val = pre_indexing(X_val,k).toarray()\n",
    "        alphabet = all_possible_substrings(k)\n",
    "   \n",
    "    D_train = pre_indexing(X_train,k,alphabet)\n",
    "    D_val = pre_indexing(X_val,k,alphabet)\n",
    "    D_test = pre_indexing(X_test,k,alphabet)\n",
    "        \n",
    "        \n",
    "    #K_val = np.inner(D_val, D_train)\n",
    "    #K_val = K_val.astype('float')\n",
    "    \n",
    "    K_train = D_train.dot(D_train.transpose())\n",
    "    K_train = K_train.toarray().astype('float')\n",
    "    \n",
    "    K_val = D_val.dot(D_train.transpose())\n",
    "    K_val = K_val.toarray().astype('float')\n",
    "    \n",
    "    K_test = D_test.dot(D_train.transpose())\n",
    "    K_test = K_test.toarray().astype('float')\n",
    "    \n",
    "        \n",
    "    return(K_train, K_val, K_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the spectrum-kernels for our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the precomputed train_test_split that was used to compute the mismatch kernels in the other notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtr0_, Xval0_, ytr0, yval0 = train_test_split(Xtr0, Ytr0, test_size=0.2, random_state=42)\n",
    "#Xtr1_, Xval1_, ytr1, yval1 = train_test_split(Xtr1, Ytr1, test_size=0.2, random_state=42)\n",
    "#Xtr2_, Xval2_, ytr2, yval2 = train_test_split(Xtr2, Ytr2, test_size=0.2, random_state=42)\n",
    "#\n",
    "train_idx_0 = np.load(\"train_test_split/train_idx_0.npy\").astype(int)\n",
    "train_idx_1 = np.load(\"train_test_split/train_idx_1.npy\").astype(int)\n",
    "train_idx_2 = np.load(\"train_test_split/train_idx_2.npy\").astype(int)\n",
    "\n",
    "val_idx_0 = np.load(\"train_test_split/val_idx_0.npy\").astype(int)\n",
    "val_idx_1 = np.load(\"train_test_split/val_idx_1.npy\").astype(int)\n",
    "val_idx_2 = np.load(\"train_test_split/val_idx_2.npy\").astype(int)\n",
    "\n",
    "Xtr0_ = Xtr0[train_idx_0]\n",
    "Xtr1_ = Xtr1[train_idx_1 - 2000]\n",
    "Xtr2_ = Xtr2[train_idx_2 - 4000]\n",
    "\n",
    "ytr0 = Ytr0[train_idx_0]\n",
    "ytr1 = Ytr1[train_idx_1 - 2000]\n",
    "ytr2 = Ytr2[train_idx_2 - 4000]\n",
    "\n",
    "\n",
    "Xval0_ = Xtr0[val_idx_0]\n",
    "Xval1_ = Xtr1[val_idx_1 - 2000]\n",
    "Xval2_ = Xtr2[val_idx_2 - 4000]\n",
    "\n",
    "yval0 = Ytr0[val_idx_0]\n",
    "yval1 = Ytr1[val_idx_1 - 2000]\n",
    "yval2 = Ytr2[val_idx_2 - 4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xte0 = features_into_array(\"data/Xte0.csv\")\n",
    "Xte1 = features_into_array(\"data/Xte1.csv\")\n",
    "Xte2 = features_into_array(\"data/Xte2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 0.24821901321411133 seconds ---\n",
      "--- Computed kernel in 6.105154037475586 seconds ---\n",
      "--- Computed kernel in 6.009521245956421 seconds ---\n",
      "--- Computed kernel in 7.061125040054321 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k = 8\n",
    "start_time = time.time()\n",
    "alphabet_8 = all_possible_substrings(k)\n",
    "print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "\n",
    "K_tr0, K_val0, K_te0 = spectrum_kernel(Xtr0_, Xval0_, Xte0, k, alphabet=alphabet_8,)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "K_tr1, K_val1, K_te1 = spectrum_kernel(Xtr1_, Xval1_, Xte1, k, alphabet=alphabet_8)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "K_tr2, K_val2, K_te2 = spectrum_kernel(Xtr2_, Xval2_, Xte2, k, alphabet=alphabet_8)\n",
    "print(\"--- Computed kernel in %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-Validation\n",
    "(runs to make sure everything is ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* KRR for dataset 0*************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 803.2332, accuracy = 1.000000\n",
      "Validation: loss = 121.7379, accuracy = 0.585000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 803.2332, accuracy = 1.000000\n",
      "Validation: loss = 121.7379, accuracy = 0.585000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 803.2332, accuracy = 1.000000\n",
      "Validation: loss = 121.7379, accuracy = 0.585000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 803.2330, accuracy = 1.000000\n",
      "Validation: loss = 121.7379, accuracy = 0.585000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 803.2318, accuracy = 1.000000\n",
      "Validation: loss = 121.7378, accuracy = 0.585000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 803.2193, accuracy = 1.000000\n",
      "Validation: loss = 121.7375, accuracy = 0.585000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 803.0939, accuracy = 1.000000\n",
      "Validation: loss = 121.7344, accuracy = 0.585000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 801.8446, accuracy = 1.000000\n",
      "Validation: loss = 121.7038, accuracy = 0.585000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 789.7625, accuracy = 1.000000\n",
      "Validation: loss = 121.4197, accuracy = 0.590000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 698.6984, accuracy = 1.000000\n",
      "Validation: loss = 119.7462, accuracy = 0.592500\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 495.3750, accuracy = 0.935000\n",
      "Validation: loss = 122.5921, accuracy = 0.512500\n",
      "***********lambda = 1***********\n",
      "Training: loss = 601.3406, accuracy = 0.524375\n",
      "Validation: loss = 163.8494, accuracy = 0.497500\n",
      "***********lambda = 10***********\n",
      "Training: loss = 735.1287, accuracy = 0.524375\n",
      "Validation: loss = 195.0546, accuracy = 0.497500\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 804.9071, accuracy = 1.000000\n",
      "Validation: loss = 120.5775, accuracy = 0.610000\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 804.9071, accuracy = 1.000000\n",
      "Validation: loss = 120.5775, accuracy = 0.610000\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 804.9071, accuracy = 1.000000\n",
      "Validation: loss = 120.5775, accuracy = 0.610000\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 804.9069, accuracy = 1.000000\n",
      "Validation: loss = 120.5775, accuracy = 0.610000\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 804.9057, accuracy = 1.000000\n",
      "Validation: loss = 120.5775, accuracy = 0.610000\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 804.8934, accuracy = 1.000000\n",
      "Validation: loss = 120.5772, accuracy = 0.610000\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 804.7707, accuracy = 1.000000\n",
      "Validation: loss = 120.5747, accuracy = 0.610000\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 803.5474, accuracy = 1.000000\n",
      "Validation: loss = 120.5493, accuracy = 0.607500\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 791.6643, accuracy = 1.000000\n",
      "Validation: loss = 120.2996, accuracy = 0.607500\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 699.8406, accuracy = 1.000000\n",
      "Validation: loss = 118.4234, accuracy = 0.600000\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 490.7469, accuracy = 0.954375\n",
      "Validation: loss = 120.4907, accuracy = 0.512500\n",
      "***********lambda = 1***********\n",
      "Training: loss = 615.9863, accuracy = 0.505000\n",
      "Validation: loss = 167.8342, accuracy = 0.477500\n",
      "***********lambda = 10***********\n",
      "Training: loss = 764.7872, accuracy = 0.505000\n",
      "Validation: loss = 202.8071, accuracy = 0.477500\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "***********lambda = 0***********\n",
      "Training: loss = 1298.6137, accuracy = 0.993750\n",
      "Validation: loss = 140.6644, accuracy = 0.702500\n",
      "***********lambda = 1e-10***********\n",
      "Training: loss = 804.2479, accuracy = 1.000000\n",
      "Validation: loss = 132.2482, accuracy = 0.742500\n",
      "***********lambda = 1e-09***********\n",
      "Training: loss = 804.2479, accuracy = 1.000000\n",
      "Validation: loss = 132.2482, accuracy = 0.742500\n",
      "***********lambda = 1e-08***********\n",
      "Training: loss = 804.2478, accuracy = 1.000000\n",
      "Validation: loss = 132.2482, accuracy = 0.742500\n",
      "***********lambda = 1e-07***********\n",
      "Training: loss = 804.2467, accuracy = 1.000000\n",
      "Validation: loss = 132.2482, accuracy = 0.742500\n",
      "***********lambda = 1e-06***********\n",
      "Training: loss = 804.2361, accuracy = 1.000000\n",
      "Validation: loss = 132.2477, accuracy = 0.742500\n",
      "***********lambda = 1e-05***********\n",
      "Training: loss = 804.1300, accuracy = 1.000000\n",
      "Validation: loss = 132.2426, accuracy = 0.742500\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 803.0726, accuracy = 1.000000\n",
      "Validation: loss = 132.1930, accuracy = 0.742500\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 792.8404, accuracy = 1.000000\n",
      "Validation: loss = 131.7357, accuracy = 0.740000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 714.3595, accuracy = 1.000000\n",
      "Validation: loss = 128.3676, accuracy = 0.732500\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 519.9541, accuracy = 0.967500\n",
      "Validation: loss = 120.8860, accuracy = 0.670000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 621.4400, accuracy = 0.492500\n",
      "Validation: loss = 149.0669, accuracy = 0.537500\n",
      "***********lambda = 10***********\n",
      "Training: loss = 780.9297, accuracy = 0.492500\n",
      "Validation: loss = 179.1431, accuracy = 0.537500\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0] + [10**i for i in range(-10,2)]\n",
    "\n",
    "print(\"************* KRR for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KRR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = KRR(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = KRR(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************KLR for dataset 0*************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3155, accuracy = 1.000000\n",
      "Validation: loss = 0.6535, accuracy = 0.595000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3338, accuracy = 1.000000\n",
      "Validation: loss = 0.6525, accuracy = 0.602500\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.4359, accuracy = 0.996875\n",
      "Validation: loss = 0.6513, accuracy = 0.622500\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.6083, accuracy = 0.978750\n",
      "Validation: loss = 0.6642, accuracy = 0.632500\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6782, accuracy = 0.951875\n",
      "Validation: loss = 0.6850, accuracy = 0.610000\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3156, accuracy = 1.000000\n",
      "Validation: loss = 0.6436, accuracy = 0.640000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3343, accuracy = 1.000000\n",
      "Validation: loss = 0.6448, accuracy = 0.637500\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.4422, accuracy = 1.000000\n",
      "Validation: loss = 0.6553, accuracy = 0.662500\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.6243, accuracy = 0.996250\n",
      "Validation: loss = 0.6800, accuracy = 0.660000\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6846, accuracy = 0.990625\n",
      "Validation: loss = 0.6912, accuracy = 0.642500\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "***********lambda = 0.0001***********\n",
      "Training: loss = 0.3152, accuracy = 1.000000\n",
      "Validation: loss = 0.5820, accuracy = 0.725000\n",
      "***********lambda = 0.001***********\n",
      "Training: loss = 0.3312, accuracy = 1.000000\n",
      "Validation: loss = 0.5831, accuracy = 0.730000\n",
      "***********lambda = 0.01***********\n",
      "Training: loss = 0.4230, accuracy = 0.998750\n",
      "Validation: loss = 0.5952, accuracy = 0.737500\n",
      "***********lambda = 0.1***********\n",
      "Training: loss = 0.5930, accuracy = 0.985000\n",
      "Validation: loss = 0.6374, accuracy = 0.707500\n",
      "***********lambda = 1***********\n",
      "Training: loss = 0.6740, accuracy = 0.964375\n",
      "Validation: loss = 0.6784, accuracy = 0.697500\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-4,1)]\n",
    "\n",
    "print(\"*************KLR for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = KLR(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas, tresh=1e-8)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = KLR(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas, tresh=1e-8)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = KLR(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas, tresh= 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* SVM for dataset 0*************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.977640, accuracy = 0.936250\n",
      "Validation: loss = 0.986505, accuracy = 0.605000\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.813766, accuracy = 0.956250\n",
      "Validation: loss = 0.902269, accuracy = 0.617500\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.126440, accuracy = 0.988125\n",
      "Validation: loss = 0.842382, accuracy = 0.635000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.881470, accuracy = 0.602500\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.881467, accuracy = 0.602500\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.881474, accuracy = 0.602500\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.881467, accuracy = 0.602500\n",
      "\n",
      "\n",
      "************* SVM for dataset 1 *************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.988679, accuracy = 0.987500\n",
      "Validation: loss = 0.997349, accuracy = 0.642500\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.886789, accuracy = 0.988125\n",
      "Validation: loss = 0.973488, accuracy = 0.640000\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.122537, accuracy = 0.998750\n",
      "Validation: loss = 0.863671, accuracy = 0.662500\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.861784, accuracy = 0.640000\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.861787, accuracy = 0.640000\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.861786, accuracy = 0.640000\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.861787, accuracy = 0.640000\n",
      "\n",
      "\n",
      "************* SVM for dataset 2 *************\n",
      "\n",
      "---------------  lambda = 0.0001  ---------------\n",
      "Training: loss = 0.970690, accuracy = 0.956875\n",
      "Validation: loss = 0.975811, accuracy = 0.702500\n",
      "---------------  lambda = 0.001  ---------------\n",
      "Training: loss = 0.775768, accuracy = 0.958125\n",
      "Validation: loss = 0.838297, accuracy = 0.692500\n",
      "---------------  lambda = 0.01  ---------------\n",
      "Training: loss = 0.101139, accuracy = 0.995625\n",
      "Validation: loss = 0.696163, accuracy = 0.730000\n",
      "---------------  lambda = 0.1  ---------------\n",
      "Training: loss = 0.000178, accuracy = 1.000000\n",
      "Validation: loss = 0.698956, accuracy = 0.730000\n",
      "---------------  lambda = 1  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.698976, accuracy = 0.727500\n",
      "---------------  lambda = 10  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.698976, accuracy = 0.727500\n",
      "---------------  lambda = 100  ---------------\n",
      "Training: loss = 0.000000, accuracy = 1.000000\n",
      "Validation: loss = 0.698976, accuracy = 0.727500\n"
     ]
    }
   ],
   "source": [
    "lambdas = [10**i for i in range(-4, 3)]\n",
    "print(\"************* SVM for dataset 0*************\\n\")\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambdas)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 1 *************\\n\")\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = SVM(K_tr1, ytr1[:,1], K_val1, yval1[:,1],lambdas)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"************* SVM for dataset 2 *************\\n\")\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = SVM(K_tr2, ytr2[:,1], K_val2, yval2[:,1],lambdas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Sklearn SVM on dataset 0 ***************\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'K_tr0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-384ea79946a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m\"Sklearn SVM on dataset 0 \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_tr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_tr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_val0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K_tr0' is not defined"
     ]
    }
   ],
   "source": [
    "# sanity check to see that our SVM does a good job\n",
    "# C = 1/(2*n*lambda) \n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='precomputed', C =1.)\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 0 \" + \"*\"*15)\n",
    "clf.fit(K_tr0, ytr0[:,1])\n",
    "print(clf.score(K_tr0, ytr0[:,1]))\n",
    "print(clf.score(K_val0, yval0[:,1]))\n",
    "lambd_C = [1]\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(K_tr0, ytr0[:,1], K_val0, yval0[:,1], lambd_C)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 1 \" + \"*\"*15)\n",
    "clf.fit(K_tr1, ytr1[:,1])\n",
    "print(clf.score(K_tr1, ytr1[:,1]))\n",
    "print(clf.score(K_val1, yval1[:,1]))\n",
    "lambd_C = [1]\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = SVM(K_tr1, ytr1[:,1], K_val1, yval1[:,1], lambd_C)\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 2 \" + \"*\"*15)\n",
    "clf.fit(K_tr2, ytr2[:,1])\n",
    "print(clf.score(K_tr2, ytr2[:,1]))\n",
    "print(clf.score(K_val2, yval2[:,1]))\n",
    "lambd_C = [1]\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = SVM(K_tr2, ytr2[:,1], K_val2, yval2[:,1], lambd_C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay cool almost there let's do gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************treating k=3***************\n",
      "--- Found alphabet in 0.0001838207244873047 seconds ---\n",
      "--- Computed all the kernels in 4.689929246902466 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=4***************\n",
      "--- Found alphabet in 0.0005118846893310547 seconds ---\n",
      "--- Computed all the kernels in 4.623594045639038 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=5***************\n",
      "--- Found alphabet in 0.0011050701141357422 seconds ---\n",
      "--- Computed all the kernels in 4.013540029525757 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=6***************\n",
      "--- Found alphabet in 0.005137205123901367 seconds ---\n",
      "--- Computed all the kernels in 4.9780778884887695 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=7***************\n",
      "--- Found alphabet in 0.03323197364807129 seconds ---\n",
      "--- Computed all the kernels in 6.995905876159668 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=8***************\n",
      "--- Found alphabet in 0.16201400756835938 seconds ---\n",
      "--- Computed all the kernels in 16.233572721481323 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=9***************\n",
      "--- Found alphabet in 0.49854207038879395 seconds ---\n",
      "--- Computed all the kernels in 49.17831802368164 seconds ---\n",
      "\n",
      "\n",
      "\n",
      "***************treating k=10***************\n",
      "--- Found alphabet in 2.0639700889587402 seconds ---\n",
      "--- Computed all the kernels in 228.87142205238342 seconds ---\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Kernels_tr_0 = []\n",
    "Kernels_val_0 = []\n",
    "Kernels_te_0 = []\n",
    "\n",
    "Kernels_tr_1 = []\n",
    "Kernels_val_1 = []\n",
    "Kernels_te_1 = []\n",
    "\n",
    "Kernels_tr_2 = []\n",
    "Kernels_val_2 = []\n",
    "Kernels_te_2 = []\n",
    "\n",
    "\n",
    "for k in range(3,11):\n",
    "    print(\"*\"*15 + \"treating k=\" + str(k) + 15*\"*\")\n",
    "    start_time = time.time()\n",
    "    alphabet_k = all_possible_substrings(k)\n",
    "    print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    K_tr0, K_val0, K_te0 = spectrum_kernel(Xtr0_, Xval0_, Xte0, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_0 += [K_tr0]\n",
    "    Kernels_val_0 += [K_val0]\n",
    "    Kernels_te_0 += [K_te0]\n",
    "    \n",
    "    K_tr1, K_val1, K_te1 = spectrum_kernel(Xtr1_, Xval1_, Xte1, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_1 += [K_tr1]\n",
    "    Kernels_val_1 += [K_val1]\n",
    "    Kernels_te_1 += [K_te1]\n",
    "    \n",
    "    K_tr2, K_val2, K_te2 = spectrum_kernel(Xtr2_, Xval2_, Xte2, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_2 += [K_tr2]\n",
    "    Kernels_val_2 += [K_val2]\n",
    "    Kernels_te_2 += [K_te2]\n",
    "    \n",
    "    print(\"--- Computed all the kernels in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************treating k = 5***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.002, kernel='precomputed')\n",
      "training score for k = 5  0.72\n",
      "validation score for k = 5  0.65\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.005, kernel='precomputed')\n",
      "training score for k = 5  0.791875\n",
      "validation score for k = 5  0.64\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.006, kernel='precomputed')\n",
      "training score for k = 5  0.836875\n",
      "validation score for k = 5  0.7075\n",
      "\n",
      "\n",
      "***************treating k = 6***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.003, kernel='precomputed')\n",
      "training score for k = 6  0.791875\n",
      "validation score for k = 6  0.6425\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.004, kernel='precomputed')\n",
      "training score for k = 6  0.86625\n",
      "validation score for k = 6  0.6375\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.008, kernel='precomputed')\n",
      "training score for k = 6  0.926875\n",
      "validation score for k = 6  0.7125\n",
      "\n",
      "\n",
      "***************treating k = 7***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.009000000000000001, kernel='precomputed')\n",
      "training score for k = 7  0.968125\n",
      "validation score for k = 7  0.6725\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.007, kernel='precomputed')\n",
      "training score for k = 7  0.97375\n",
      "validation score for k = 7  0.6625\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.01, kernel='precomputed')\n",
      "training score for k = 7  0.98375\n",
      "validation score for k = 7  0.705\n",
      "\n",
      "\n",
      "***************treating k = 8***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.01, kernel='precomputed')\n",
      "training score for k = 8  0.9875\n",
      "validation score for k = 8  0.6275\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.009000000000000001, kernel='precomputed')\n",
      "training score for k = 8  0.998125\n",
      "validation score for k = 8  0.6575\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.08, kernel='precomputed')\n",
      "training score for k = 8  1.0\n",
      "validation score for k = 8  0.7225\n",
      "\n",
      "\n",
      "***************treating k = 9***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 9  0.9975\n",
      "validation score for k = 9  0.605\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.01, kernel='precomputed')\n",
      "training score for k = 9  1.0\n",
      "validation score for k = 9  0.6175\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 9  0.99875\n",
      "validation score for k = 9  0.7175\n",
      "\n",
      "\n",
      "***************treating k = 10***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 10  0.99875\n",
      "validation score for k = 10  0.5925\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 10  1.0\n",
      "validation score for k = 10  0.585\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "SVC(C=0.02, kernel='precomputed')\n",
      "training score for k = 10  0.99875\n",
      "validation score for k = 10  0.66\n",
      "\n",
      "\n",
      "***************treating k = 11***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-451e86abc7fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" treating dataset 0 \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mgs_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernels_tr_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"training score for k = {k+3} \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernels_tr_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "values_C = [j*10**i for i in range(-5,3) for j in range(1,10)]\n",
    "parameters = {'C': values_C}\n",
    "svm__ = svm.SVC(kernel='precomputed')\n",
    "gs_k = GridSearchCV(svm__, param_grid=parameters, refit=True, verbose=0)\n",
    "\n",
    "for k in range(2,9):\n",
    "    \n",
    "        \n",
    "    print(\"*\"*15 + \"treating k = \" + str(k+3) + 15*\"*\")\n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 0 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_0[k], ytr0[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_0[k], ytr0[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_0[k], yval0[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 1 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_1[k], ytr1[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_1[k], ytr1[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_1[k], yval1[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 2 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_2[k], ytr2[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_2[k], ytr2[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_2[k], yval2[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the train kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "KTR0 = np.asarray(Kernels_tr_0[2:])\n",
    "KTR1 = np.asarray(Kernels_tr_1[2:])\n",
    "KTR2 = np.asarray(Kernels_tr_2[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1600, 1600)\n",
      "(6, 1600, 1600)\n",
      "(6, 1600, 1600)\n"
     ]
    }
   ],
   "source": [
    "print(KTR0.shape)\n",
    "print(KTR1.shape)\n",
    "print(KTR2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"spectrum/K_train0.npy\", KTR0)\n",
    "np.save(\"spectrum/K_train1.npy\", KTR1)\n",
    "np.save(\"spectrum/K_train2.npy\", KTR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the validation kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "KVAL0 = np.asarray(Kernels_val_0[2:])\n",
    "KVAL1 = np.asarray(Kernels_val_1[2:])\n",
    "KVAL2 = np.asarray(Kernels_val_2[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 400, 1600)\n",
      "(6, 400, 1600)\n",
      "(6, 400, 1600)\n"
     ]
    }
   ],
   "source": [
    "print(KVAL0.shape)\n",
    "print(KVAL1.shape)\n",
    "print(KVAL2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"spectrum/K_val0.npy\", KVAL0)\n",
    "np.save(\"spectrum/K_val1.npy\", KVAL1)\n",
    "np.save(\"spectrum/K_val2.npy\", KVAL2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the test kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "KTE0 = np.asarray(Kernels_te_0[2:])\n",
    "KTE1 = np.asarray(Kernels_te_1[2:])\n",
    "KTE2 = np.asarray(Kernels_te_2[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1000, 1600)\n",
      "(6, 1000, 1600)\n",
      "(6, 1000, 1600)\n"
     ]
    }
   ],
   "source": [
    "print(KTE0.shape)\n",
    "print(KTE1.shape)\n",
    "print(KTE2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"spectrum/K_te0.npy\", KTE0)\n",
    "np.save(\"spectrum/K_te1.npy\", KTE1)\n",
    "np.save(\"spectrum/K_te2.npy\", KTE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do GridSearch using KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************treating k = 5***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "KernelRidge(alpha=500, kernel='precomputed')\n",
      "training score for k = 5  0.28300186354446866\n",
      "validation score for k = 5  0.1223365457749519\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "KernelRidge(alpha=300, kernel='precomputed')\n",
      "training score for k = 5  0.36037269519040716\n",
      "validation score for k = 5  0.1328436796250635\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "KernelRidge(alpha=400, kernel='precomputed')\n",
      "training score for k = 5  0.42481870027422874\n",
      "validation score for k = 5  0.2579091857473338\n",
      "\n",
      "\n",
      "***************treating k = 6***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "KernelRidge(alpha=300, kernel='precomputed')\n",
      "training score for k = 6  0.42659522546433337\n",
      "validation score for k = 6  0.11325856461831074\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "KernelRidge(alpha=200, kernel='precomputed')\n",
      "training score for k = 6  0.517923299627612\n",
      "validation score for k = 6  0.14588520105392833\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "KernelRidge(alpha=200, kernel='precomputed')\n",
      "training score for k = 6  0.6047978867292789\n",
      "validation score for k = 6  0.31064203420142966\n",
      "\n",
      "\n",
      "***************treating k = 7***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "KernelRidge(alpha=90, kernel='precomputed')\n",
      "training score for k = 7  0.7445321203964739\n",
      "validation score for k = 7  0.08679146827312967\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "KernelRidge(alpha=70, kernel='precomputed')\n",
      "training score for k = 7  0.8004902608086785\n",
      "validation score for k = 7  0.11998920501336674\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "KernelRidge(alpha=40, kernel='precomputed')\n",
      "training score for k = 7  0.9113964815126323\n",
      "validation score for k = 7  0.3078537432595987\n",
      "\n",
      "\n",
      "***************treating k = 8***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "KernelRidge(alpha=4, kernel='precomputed')\n",
      "training score for k = 8  0.9977815393709502\n",
      "validation score for k = 8  0.005881828689841773\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "KernelRidge(alpha=1e-05, kernel='precomputed')\n",
      "training score for k = 8  0.9999999999999865\n",
      "validation score for k = 8  0.06152568184662055\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "KernelRidge(alpha=0.9, kernel='precomputed')\n",
      "training score for k = 8  0.9998978071692503\n",
      "validation score for k = 8  0.2932830407935402\n",
      "\n",
      "\n",
      "***************treating k = 9***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "KernelRidge(alpha=1e-05, kernel='precomputed')\n",
      "training score for k = 9  0.9999999999999845\n",
      "validation score for k = 9  -0.1557971397258855\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "KernelRidge(alpha=1e-05, kernel='precomputed')\n",
      "training score for k = 9  0.999999999999986\n",
      "validation score for k = 9  -0.1364767487749301\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "KernelRidge(alpha=1e-05, kernel='precomputed')\n",
      "training score for k = 9  0.999999999999987\n",
      "validation score for k = 9  0.20212774571259318\n",
      "\n",
      "\n",
      "***************treating k = 10***************\n",
      "\n",
      "--------------- treating dataset 0 ---------------\n",
      "KernelRidge(alpha=1e-05, kernel='precomputed')\n",
      "training score for k = 10  0.9999999999999813\n",
      "validation score for k = 10  -0.49707497053333105\n",
      "\n",
      "--------------- treating dataset 1 ---------------\n",
      "KernelRidge(alpha=1e-05, kernel='precomputed')\n",
      "training score for k = 10  0.9999999999999825\n",
      "validation score for k = 10  -0.4738749782066438\n",
      "\n",
      "--------------- treating dataset 2 ---------------\n",
      "KernelRidge(alpha=1e-05, kernel='precomputed')\n",
      "training score for k = 10  0.9999999999999839\n",
      "validation score for k = 10  -0.07303639226967706\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "values_alpha = [j*10**i for i in range(-5,3) for j in range(1,10)]\n",
    "parameters = {'alpha': values_alpha}\n",
    "krr = KernelRidge(kernel='precomputed')\n",
    "gs_krr = GridSearchCV(krr, param_grid=parameters, refit=True, verbose=0)\n",
    "\n",
    "for k in range(2,8):\n",
    "    \n",
    "        \n",
    "    print(\"*\"*15 + \"treating k = \" + str(k+3) + 15*\"*\")\n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 0 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_krr.fit(Kernels_tr_0[k], ytr0[:,1])\n",
    "    print(gs_krr.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_krr.score(Kernels_tr_0[k], ytr0[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_krr.score(Kernels_val_0[k], yval0[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 1 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_krr.fit(Kernels_tr_1[k], ytr1[:,1])\n",
    "    print(gs_krr.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_krr.score(Kernels_tr_1[k], ytr1[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_krr.score(Kernels_val_1[k], yval1[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 2 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_krr.fit(Kernels_tr_2[k], ytr2[:,1])\n",
    "    print(gs_krr.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_krr.score(Kernels_tr_2[k], ytr2[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_krr.score(Kernels_val_2[k], yval2[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forget it its trash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets do for k = 11 and 12 too\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************treating k=11***************\n",
      "--- Found alphabet in 11.176947116851807 seconds ---\n"
     ]
    }
   ],
   "source": [
    "Kernels_tr_0_12 = []\n",
    "Kernels_val_0_12 = []\n",
    "Kernels_te_0_12 = []\n",
    "\n",
    "Kernels_tr_1_12 = []\n",
    "Kernels_val_1_12 = []\n",
    "Kernels_te_1_12 = []\n",
    "\n",
    "Kernels_tr_2_12 = []\n",
    "Kernels_val_2_12 = []\n",
    "Kernels_te_2_12 = []\n",
    "\n",
    "\n",
    "for k in range(11,13):\n",
    "    print(\"*\"*15 + \"treating k=\" + str(k) + 15*\"*\")\n",
    "    start_time = time.time()\n",
    "    alphabet_k = all_possible_substrings(k)\n",
    "    print(\"--- Found alphabet in %s seconds ---\" % (time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "    K_tr0, K_val0, K_te0 = spectrum_kernel(Xtr0_, Xval0_, Xte0, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_0_12 += [K_tr0]\n",
    "    Kernels_val_0_12 += [K_val0]\n",
    "    Kernels_te_0_12 += [K_te0]\n",
    "    \n",
    "    K_tr1, K_val1, K_te1 = spectrum_kernel(Xtr1_, Xval1_, Xte1, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_1_12 += [K_tr1]\n",
    "    Kernels_val_1_12 += [K_val1]\n",
    "    Kernels_te_1_12 += [K_te1]\n",
    "    \n",
    "    K_tr2, K_val2, K_te2 = spectrum_kernel(Xtr2_, Xval2_, Xte2, k, alphabet=alphabet_k)\n",
    "    Kernels_tr_2_12 += [K_tr2]\n",
    "    Kernels_val_2_12 += [K_val2]\n",
    "    Kernels_te_2_12 += [K_te2]\n",
    "    \n",
    "    print(\"--- Computed all the kernels in %s seconds ---\" % (time.time() - start_time))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "values_C = [j*10**i for i in range(-5,3) for j in range(1,10)]\n",
    "parameters = {'C': values_C}\n",
    "svm__ = svm.SVC(kernel='precomputed')\n",
    "gs_k = GridSearchCV(svm__, param_grid=parameters, refit=True, verbose=0)\n",
    "\n",
    "for k in range(2):\n",
    "    \n",
    "        \n",
    "    print(\"*\"*15 + \"treating k = \" + str(k+11) + 15*\"*\")\n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 0 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_0_12[k], ytr0[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_0_12[k], ytr0[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_0_12[k], yval0[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 1 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_1_12[k], ytr1[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_1_12[k], ytr1[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_1_12[k], yval1[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\"*15 + \" treating dataset 2 \"+ 15*\"-\")\n",
    "    \n",
    "    gs_k.fit(Kernels_tr_2_12[k], ytr2[:,1])\n",
    "    print(gs_k.best_estimator_)\n",
    "    print(f\"training score for k = {k+3} \", gs_k.score(Kernels_tr_2_12[k], ytr2[:,1]))\n",
    "    print(f\"validation score for k = {k+3} \", gs_k.score(Kernels_val_2_12[k], yval2[:,1]))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found alphabet in 70.059677839279174805 seconds ---\n",
      "--- Found alphabet in 90.7294759750366211 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "alphabet_7 = all_possible_substrings(7)\n",
    "print(\"--- Found alphabet in 7%s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "alphabet_9 = all_possible_substrings(9)\n",
    "print(\"--- Found alphabet in 9%s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "\n",
    "K_tr0, K_val0, K_te0 = spectrum_kernel(Xtr0_, Xval0_, Xte0, 7, alphabet=alphabet_7)\n",
    "K_tr1, K_val1, K_te1 = spectrum_kernel(Xtr1_, Xval1_, Xte1, 7, alphabet=alphabet_7)\n",
    "K_tr2, K_val2, K_te2 = spectrum_kernel(Xtr2_, Xval2_, Xte2, 9, alphabet=alphabet_9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************Sklearn SVM on dataset 0 ***************\n",
      "0.968125\n",
      "0.6725\n",
      "---------------  lambda = 0.009  ---------------\n",
      "Training: loss = 0.227732, accuracy = 0.970625\n",
      "Validation: loss = 0.795442, accuracy = 0.657500\n",
      "\n",
      "\n",
      "\n",
      "***************Sklearn SVM on dataset 1 ***************\n",
      "0.97375\n",
      "0.6625\n",
      "---------------  lambda = 0.007  ---------------\n",
      "Training: loss = 0.316770, accuracy = 0.974375\n",
      "Validation: loss = 0.831072, accuracy = 0.660000\n",
      "\n",
      "\n",
      "\n",
      "***************Sklearn SVM on dataset 2 ***************\n",
      "1.0\n",
      "0.7225\n",
      "---------------  lambda = 0.08  ---------------\n",
      "Training: loss = 0.000222, accuracy = 1.000000\n",
      "Validation: loss = 0.732678, accuracy = 0.717500\n"
     ]
    }
   ],
   "source": [
    "# sanity check to see that our SVM does a good job\n",
    "from sklearn import svm\n",
    "clf0 = svm.SVC(kernel='precomputed', C = 0.009)\n",
    "clf1 = svm.SVC(kernel='precomputed', C = 0.007)\n",
    "clf2 = svm.SVC(kernel='precomputed', C = 0.08)\n",
    "\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 0 \" + \"*\"*15)\n",
    "clf0.fit(K_tr0, ytr0[:,1])\n",
    "print(clf0.score(K_tr0, ytr0[:,1]))\n",
    "print(clf0.score(K_val0, yval0[:,1]))\n",
    "alphas_tr0, loss_tr0, acc_0, loss_val0, acc_val0 = SVM(K_tr0, ytr0[:,1], K_val0, yval0[:,1], [0.009])\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 1 \" + \"*\"*15)\n",
    "clf1.fit(K_tr1, ytr1[:,1])\n",
    "print(clf1.score(K_tr1, ytr1[:,1]))\n",
    "print(clf1.score(K_val1, yval1[:,1]))\n",
    "alphas_tr1, loss_tr1, acc_1, loss_val1, acc_val1 = SVM(K_tr1, ytr1[:,1], K_val1, yval1[:,1], [0.007])\n",
    "\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"*\"*15  + \"Sklearn SVM on dataset 2 \" + \"*\"*15)\n",
    "clf2.fit(K_tr2, ytr2[:,1])\n",
    "print(clf2.score(K_tr2, ytr2[:,1]))\n",
    "print(clf2.score(K_val2, yval2[:,1]))\n",
    "alphas_tr2, loss_tr2, acc_2, loss_val2, acc_val2 = SVM(K_tr2, ytr2[:,1], K_val2, yval2[:,1], [0.08])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def write_predictions_csv_good(test_kernels, test_alphas, path, mode=\"SVM\"):\n",
    "    \n",
    "    n = test_kernels[0].shape[0]\n",
    "    print(n)\n",
    "    predictions = np.zeros(3*n, dtype=int)\n",
    "    \n",
    "    for i in range(3):\n",
    "        y_pred = test_kernels[i] @ test_alphas[i]\n",
    "        if mode == 'SVM':\n",
    "            print(\"entered mode SVM\")\n",
    "            y_pred_ = np.ones(n)\n",
    "            y_pred_[y_pred < 0] = 0\n",
    "        else:\n",
    "            y_pred_ = np.zeros(n)\n",
    "            y_pred_[y_pred >= 0.5] = 1\n",
    "   \n",
    "        predictions[n*i:n*(i+1)] = y_pred_\n",
    "    \n",
    "    #predictions = predictions.astype(int)\n",
    "    pred = pd.DataFrame({\"Bound\" : predictions})\n",
    "    print(\"saving predictions\")\n",
    "    pred.to_csv(path, index=True,index_label=\"Id\")\n",
    "    #np.savetxt(\"data/Ytest_KRR.csv\", predictions, header = \"Id, Bound\", delimiter =\",\")\n",
    "    print(\"saved predictions\")\n",
    "    return(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
